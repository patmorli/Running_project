{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":1376,"status":"error","timestamp":1677627509242,"user":{"displayName":"Patrick Mayerhofer","userId":"16899985720775247572"},"user_tz":480},"id":"fLUutxLOBW3w","outputId":"0819b18d-7b23-4791-c05b-9dd404e2a606"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found GPU at: /device:GPU:0\n","/content/drive/My Drive/Running Plantiga Project/Data\n","Train: 207\n","Validation: 69\n","Test: 69\n"]},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-72fee5dfdaaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    771\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} /content/drive/My Drive/Running Plantiga Project/Data/Prepared/tfrecords/8k_250_0/Treadmill/speed0/SENSOR096.tfrecords; No such file or directory [Op:IteratorGetNext]"]}],"source":["import os, os.path, datetime\n","import keras\n","from google.colab import drive \n","import tensorflow as tf\n","import numpy as np\n","from keras import layers, models\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense,Flatten,Conv3D\n","from tensorflow.keras.optimizers import Adam\n","import keras\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_curve, PrecisionRecallDisplay\n","import matplotlib.pyplot as plt\n","drive.mount('/content/drive') \n","\n","# import PredictPower_functions\n","#import PredictPower_functions as ppf\n","#import openloop_algorithms as oa\n","\n","\n","#check if GPU is available\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","\n","\"\"\"some variables\"\"\"\n","data_name = \"8k_250_0\"\n","subjects = [34,35,36,37,38,40,41,42,43,45,46,48,49,52,53,54,55,58,59,60,61,62,63,66,67,68,69,70,72,73,74,77,79,80,82,84,85,87,88,89,90,91,92,93,94,95,96,98,99,100,101,102,104,105,106,107,108,110,111,112,113,114,115,116,118,119,120,122,123,125,126,127,128,130,131,132,133,135,138,139,140,142,143,146,147,150,151,154,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,173,174,176,177,179,180,182,184,185,186,188]\n","val_split = 0.2\n","test_split = 0.2\n","flag_shuffle_train = 0\n","flag_plot = 0\n","epochs = 25\n","dropout = 0.3\n","weights_to_use = \"imagenet\"\n","input_my_model = keras.Input(shape = (126,32,12,1)) #keras.Input(shape = (126,40,12,1))  #keras.Input(shape = (10000,12)) # input for first layer\n","input_resnet = keras.Input(shape=(126,32,3)) # input after my own layers into the resnet\n","resnet_trainable = True\n","final_layer_size = 4\n","\n","\n","%cd /content/drive/My\\ Drive/Running Plantiga Project/Data\n","dir_root = os.getcwd() + '/'\n","dir_tfrecords = dir_root + 'Prepared/tfrecords/' + data_name + '/Treadmill/'\n","\n","test_subjects = subjects[0:int(len(subjects)*test_split)]\n","val_subjects = subjects[int(len(subjects)*test_split):int(len(subjects)*test_split) + int(len(subjects)*val_split)]\n","train_subjects = subjects[int(len(subjects)*test_split) + int(len(subjects)*val_split):len(subjects)]\n","\n","train_filenames = list()\n","val_filenames = list()\n","test_filenames = list()\n","speeds = [0,1,2]\n","for subject in subjects:\n","    for speed in speeds:\n","        sensor = \"SENSOR\" + \"{:03d}\".format(subject)\n","        dir_tfr_data = dir_tfrecords + 'speed' + str(speed) + '/' + sensor + \".tfrecords\"\n","        if subject in test_subjects:\n","            test_filenames.append(dir_tfr_data)\n","        elif subject in val_subjects:\n","            val_filenames.append(dir_tfr_data)   \n","        else:\n","            train_filenames.append(dir_tfr_data)\n","if flag_shuffle_train:\n","    np.random.shuffle(train_filenames)\n","\n","\n","\n","print(f\"Train: {len(train_filenames)}\")\n","print(f\"Validation: {len(val_filenames)}\")\n","print(f\"Test: {len(test_filenames)}\")\n","\n","\n","for batch in tf.data.TFRecordDataset(train_filenames):\n","    print(batch)\n","    break\n","\n","\n","def parse_tfrecord_image(example):\n","  #use the same structure as above; it's kinda an outline of the structure we now want to create\n","  feature_description = {\n","      'height': tf.io.FixedLenFeature([], tf.int64),\n","      'width':tf.io.FixedLenFeature([], tf.int64),\n","      'depth':tf.io.FixedLenFeature([], tf.int64),\n","      'spectrogram_image' : tf.io.FixedLenFeature([], tf.string),\n","      'score_10k': tf.io.FixedLenFeature([], tf.int64),\n","      'seconds_10k': tf.io.FixedLenFeature([], tf.int64),\n","      'subject_id': tf.io.FixedLenFeature([], tf.int64),\n","      'bin_label': tf.io.FixedLenFeature([], tf.int64),\n","      'speed_label': tf.io.FixedLenFeature([], tf.int64)\n","    }\n","\n","  example = tf.io.parse_single_example(example, feature_description)  \n","  \n","  example['height'] = example['height']\n","  example['width'] = example['width']\n","  example['depth'] = example['depth']\n","  example['height'] = example['height']\n","  example['score_10k'] = example['score_10k']\n","  example['seconds_10k'] = example['seconds_10k']\n","  \n","  example['spectrogram_image'] = tf.io.parse_tensor(example['spectrogram_image'], out_type=tf.double)\n","  example['spectrogram_image'] = tf.reshape(example['spectrogram_image'], shape=[example['height'],example['width'],example['depth']])\n","  \n","  example['bin_label'] = example['bin_label']\n","  example['bin_label_onehot'] = tf.one_hot(example['bin_label'], depth = 2, dtype = 'int64')\n","  \n","  example['subject_id'] = example['subject_id']\n","  example['subject_id_onehot'] = tf.one_hot(example['subject_id']-1, depth = 188, dtype = 'int64')\n","\n","  \n","  example['speed_label'] = example['speed_label']\n","  example['speed_label_onehot'] = tf.one_hot(example['speed_label'], depth = 4, dtype = 'int64')\n"," \n","  \n","  return example\n","\n","\"\"\"\n","tense = list()\n","for batch in tf.data.TFRecordDataset(train_filenames).map(parse_tfrecord_rnn):\n","    #print(batch)\n","    tense.append(batch)\n","    #break\n","\"\"\"\n","\n","\n","\"\"\"prepare input and output for model\"\"\"\n","def prepare_sample(features):\n","    #image = tf.image.resize(features[\"image\"], size=(224, 224))\n","    #return image, features[\"category_id\"]\n","    spectrogram_image = features[\"spectrogram_image\"]\n","    speed_onehot = features['speed_label_onehot']\n","    \n","    return spectrogram_image, speed_onehot\n","\n","\n","(tf.data.TFRecordDataset(train_filenames)\n"," .map(parse_tfrecord_image)\n"," .map(prepare_sample)\n",")\n","\n","# my own stuff: plot some data\n","if flag_plot:\n","    print(\"not implemented yet\")\n","             \n","  \n","\n","\"\"\"fetch the data\"\"\"\n","AUTOTUNE = tf.data.AUTOTUNE\n","batch_size = 32\n","\n","\n","def get_dataset(filenames, batch_size):\n","    dataset = (\n","        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n","        .map(parse_tfrecord_image, num_parallel_calls=AUTOTUNE)\n","        .map(prepare_sample, num_parallel_calls=AUTOTUNE)\n","        .shuffle(batch_size * 10)\n","        .batch(batch_size)\n","        .prefetch(AUTOTUNE)\n","    )\n","    return dataset\n","\n","\n","get_dataset(train_filenames, batch_size)\n","\n","\"\"\"fun part\"\"\"\n","final_activation = 'sigmoid'\n","if final_layer_size > 1:\n","    final_activation = 'softmax'\n","\n","if 1:\n","    # resnet50 with weights from \"imagenet\" dataset\n","    res_model_pretrained = keras.applications.ResNet50(include_top = False, #so that we can change input and output layer\n","                                            weights=weights_to_use, \n","                                            input_tensor=input_resnet)\n","    model = Sequential()\n","    model.add(input_my_model)\n","    model.add(Conv3D(filters=16, kernel_size=(1,1,3), strides=(1,1,1), activation= 'relu'))\n","    model.add(Conv3D(filters=32, kernel_size=(1,1,3), strides=(1,1,1), activation= 'relu'))\n","    model.add(Conv3D(filters=64, kernel_size=(1,1,3), strides=(1,1,1), activation= 'relu'))\n","    model.add(Conv3D(filters=3, kernel_size=(1,1,3), strides=(1,1,1), activation= 'relu'))\n","    model.add(Conv3D(filters=1, kernel_size=(1,1,2), strides=(1,1,1), activation= 'relu'))\n","    model.add(res_model_pretrained)\n","    model.add(Flatten())\n","    model.add(layers.Dropout(dropout))\n","    model.add(layers.Dense(final_layer_size, activation=final_activation))\n","    model.summary()\n","    \n"," \n","    \n"," \n","loss_to_use = tf.keras.losses.BinaryCrossentropy()\n","if final_layer_size > 1:\n","    loss_to_use = 'categorical_crossentropy'\n","\n","model.compile(loss = loss_to_use, \n","              optimizer = \"adam\", \n","              metrics = [\"accuracy\", \n","                         tf.keras.metrics.AUC(curve = 'ROC'),\n","                         tf.keras.metrics.AUC(curve = 'PR'),\n","                         tf.keras.metrics.Precision(),\n","                         tf.keras.metrics.Recall(),\n","                         tf.keras.metrics.PrecisionAtRecall(0.8) \n","                        ]) #tf.keras.metrics.AUC(from_logits=True)\n","\n","loss_to_use = tf.keras.losses.BinaryCrossentropy()\n","if final_layer_size > 1:\n","    loss_to_use = 'categorical_crossentropy'\n","\n","model.compile(loss = loss_to_use, \n","              optimizer = \"adam\", \n","              metrics = [\"accuracy\", \n","                         tf.keras.metrics.AUC(curve = 'ROC'),\n","                         tf.keras.metrics.AUC(curve = 'PR'),\n","                         tf.keras.metrics.Precision(),\n","                         tf.keras.metrics.Recall(),\n","                         tf.keras.metrics.PrecisionAtRecall(0.8) \n","                        ]) #tf.keras.metrics.AUC(from_logits=True)\n","\n","\n","model.layers[5].trainable = resnet_trainable\n","\n","# check which parts overall are frozen\n","for i, layer in enumerate(model.layers):\n","    print(i, layer.name, \"-\", layer.trainable)\n","\n","#get_dataset(filenames, batch_size)\n","\n","\n","#examples_per_file = 128\n","\n","#steps_per_epoch = int(np.ceil(examples_per_file*len(train_filenames)/batch_size))\n","#validation_steps = int(np.ceil(examples_per_file*len(val_filenames)/batch_size))\n","#steps = int(np.ceil(examples_per_file*len(test_filenames)/batch_size))\n","#print(\"steps_per_epoch = \", steps_per_epoch)\n","#print(\"validation_steps = \", validation_steps)\n","#print(\"steps = \", steps)\n","\n","train_dataset = get_dataset(train_filenames, batch_size)\n","val_dataset = get_dataset(val_filenames, batch_size)\n","test_dataset = get_dataset(test_filenames, batch_size)\n","\n","\n","#steps_per_epoch = steps_per_epoch\n","\n","model.fit(train_dataset,\n","          validation_data = val_dataset, \n","          #steps_per_epoch = steps_per_epoch,\n","          #validation_steps = validation_steps, \n","          epochs = epochs\n","         )\n","\n","acc = model.evaluate(test_dataset, steps = len(test_filenames))\n","pred = model.predict(test_dataset)\n","\n","steps_to_take = len(test_filenames)\n","\n","pred_values_list = []\n","pred_list = []\n","true_list = []\n","true_list_onehot = []\n","\n","for x, y in test_dataset.take(steps_to_take):\n","    \n","    pred_value = model.predict(x)\n","    if final_layer_size > 1:\n","        pred = pred_value.argmax(1)\n","    else:\n","        threshold = 0.5\n","        pred = pred_value > threshold\n","    \n","    pred_values_list = pred_values_list + list(pred_value)\n","    pred_list = pred_list + list(pred)\n","    true_list = true_list + list(y.numpy().argmax(axis=1).astype(int))\n","    true_list_onehot = true_list_onehot + list(y.numpy().astype(int))\n","    \n","print('Accuracy')\n","print(accuracy_score(true_list, [x.astype(int) for x in pred_list]))\n","\n","print('Confusion Matrix')\n","print(confusion_matrix(true_list, [x.astype(int) for x in pred_list]))\n","\n","m = tf.keras.metrics.AUC(curve = 'PR')\n","m.update_state(true_list_onehot, pred_values_list)\n","m.result().numpy()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1EghLwFO7MtUL8TdBPmdsVLCXZ-_fneVZ","timestamp":1677626642143},{"file_id":"1hf3FGPyMxfbPHkBIUaqwCm8_zN0A3wmi","timestamp":1677190394051}],"authorship_tag":"ABX9TyOkecRVPhNkktFMcm7dYx7l"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}