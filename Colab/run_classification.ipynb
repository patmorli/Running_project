{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"7vIATezVjFoE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/Running Plantiga Project/Code\n","Found GPU at: /device:GPU:0\n","/content/drive/My Drive/Running Plantiga Project\n","output_variable = subject_id\n","(32, 126, 40, 12)\n","(32, 188)\n","optimizer with new learning rate\n","model checkpoint included\n","early stopping included\n","Epoch 1/20000\n","    108/Unknown - 252s 2s/step - loss: 5.1969 - accuracy: 0.0194\n","Epoch 1: val_accuracy improved from -inf to 0.05155, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 1302: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3772e-05 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.8336\n","Epoch 1303/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2246e-05 - accuracy: 1.0000\n","Epoch 1303: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2134e-05 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.8336\n","Epoch 1304/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.5826e-06 - accuracy: 1.0000\n","Epoch 1304: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 8.5826e-06 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.8395\n","Epoch 1305/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1559e-04 - accuracy: 1.0000\n","Epoch 1305: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1559e-04 - accuracy: 1.0000 - val_loss: 1.5191 - val_accuracy: 0.6863\n","Epoch 1306/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.6642e-05 - accuracy: 1.0000\n","Epoch 1306: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.6344e-05 - accuracy: 1.0000 - val_loss: 0.8817 - val_accuracy: 0.7865\n","Epoch 1307/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.4262e-05 - accuracy: 1.0000\n","Epoch 1307: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3865e-05 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.8218\n","Epoch 1308/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6295e-05 - accuracy: 1.0000\n","Epoch 1308: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6148e-05 - accuracy: 1.0000 - val_loss: 0.5754 - val_accuracy: 0.8409\n","Epoch 1309/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.2330e-05 - accuracy: 1.0000\n","Epoch 1309: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 4.2330e-05 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.8380\n","Epoch 1310/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.3737e-06 - accuracy: 1.0000\n","Epoch 1310: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 9.3409e-06 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.8233\n","Epoch 1311/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2179e-06 - accuracy: 1.0000\n","Epoch 1311: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.2179e-06 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.8262\n","Epoch 1312/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0306e-05 - accuracy: 1.0000\n","Epoch 1312: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0306e-05 - accuracy: 1.0000 - val_loss: 0.5623 - val_accuracy: 0.8380\n","Epoch 1313/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3536e-06 - accuracy: 1.0000\n","Epoch 1313: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 4.3379e-06 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.8336\n","Epoch 1314/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.4607e-06 - accuracy: 1.0000\n","Epoch 1314: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.4607e-06 - accuracy: 1.0000 - val_loss: 0.5783 - val_accuracy: 0.8351\n","Epoch 1315/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2638e-06 - accuracy: 1.0000\n","Epoch 1315: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 7.2391e-06 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.8292\n","Epoch 1316/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.4278e-06 - accuracy: 1.0000\n","Epoch 1316: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.4278e-06 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.8306\n","Epoch 1317/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.7279e-06 - accuracy: 1.0000\n","Epoch 1317: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.6835e-06 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8321\n","Epoch 1318/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4215e-05 - accuracy: 1.0000\n","Epoch 1318: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3998e-05 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.8203\n","Epoch 1319/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0565e-05 - accuracy: 1.0000\n","Epoch 1319: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0565e-05 - accuracy: 1.0000 - val_loss: 0.5349 - val_accuracy: 0.8409\n","Epoch 1320/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1241e-05 - accuracy: 1.0000\n","Epoch 1320: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1241e-05 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.8424\n","Epoch 1321/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0102e-05 - accuracy: 1.0000\n","Epoch 1321: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0102e-05 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8498\n","Epoch 1322/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3659e-04 - accuracy: 1.0000\n","Epoch 1322: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3659e-04 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.7865\n","Epoch 1323/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9156e-04 - accuracy: 1.0000\n","Epoch 1323: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9156e-04 - accuracy: 1.0000 - val_loss: 3.8443 - val_accuracy: 0.5420\n","Epoch 1324/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9630e-05 - accuracy: 1.0000\n","Epoch 1324: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.9414e-05 - accuracy: 1.0000 - val_loss: 1.6907 - val_accuracy: 0.7040\n","Epoch 1325/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5916e-05 - accuracy: 1.0000\n","Epoch 1325: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5674e-05 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.8174\n","Epoch 1326/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9139e-05 - accuracy: 1.0000\n","Epoch 1326: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 4.8733e-05 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.8351\n","Epoch 1327/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4841e-05 - accuracy: 1.0000\n","Epoch 1327: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4542e-05 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.8424\n","Epoch 1328/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.8152e-05 - accuracy: 1.0000\n","Epoch 1328: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.8152e-05 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8380\n","Epoch 1329/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3042e-05 - accuracy: 1.0000\n","Epoch 1329: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2769e-05 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8321\n","Epoch 1330/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.9598e-05 - accuracy: 1.0000\n","Epoch 1330: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.9598e-05 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8218\n","Epoch 1331/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7755e-05 - accuracy: 1.0000\n","Epoch 1331: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7755e-05 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.8409\n","Epoch 1332/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.6426e-04 - accuracy: 0.9997\n","Epoch 1332: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.6426e-04 - accuracy: 0.9997 - val_loss: 3.1489 - val_accuracy: 0.6480\n","Epoch 1333/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.6947e-05 - accuracy: 1.0000\n","Epoch 1333: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.6947e-05 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.8159\n","Epoch 1334/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.4994e-05 - accuracy: 1.0000\n","Epoch 1334: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.4423e-05 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8292\n","Epoch 1335/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4609e-05 - accuracy: 1.0000\n","Epoch 1335: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4513e-05 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8365\n","Epoch 1336/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3574e-05 - accuracy: 1.0000\n","Epoch 1336: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.3284e-05 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.8409\n","Epoch 1337/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.1124e-05 - accuracy: 1.0000\n","Epoch 1337: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 9.0336e-05 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.8365\n","Epoch 1338/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6505e-04 - accuracy: 1.0000\n","Epoch 1338: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6356e-04 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.8174\n","Epoch 1339/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5098e-05 - accuracy: 1.0000\n","Epoch 1339: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5059e-05 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8041\n","Epoch 1340/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2751e-05 - accuracy: 1.0000\n","Epoch 1340: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.2751e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.8041\n","Epoch 1341/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5054e-05 - accuracy: 1.0000\n","Epoch 1341: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.5684e-05 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.7865\n","Epoch 1342/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.0443e-05 - accuracy: 1.0000\n","Epoch 1342: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0443e-05 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.8130\n","Epoch 1343/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5641e-05 - accuracy: 1.0000\n","Epoch 1343: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5641e-05 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.8085\n","Epoch 1344/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.3039e-05 - accuracy: 1.0000\n","Epoch 1344: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 49ms/step - loss: 5.2816e-05 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.7997\n","Epoch 1345/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2929e-05 - accuracy: 1.0000\n","Epoch 1345: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2828e-05 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.8144\n","Epoch 1346/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2990e-05 - accuracy: 1.0000\n","Epoch 1346: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2789e-05 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.8159\n","Epoch 1347/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2050e-05 - accuracy: 1.0000\n","Epoch 1347: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2050e-05 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.8233\n","Epoch 1348/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.8802e-06 - accuracy: 1.0000\n","Epoch 1348: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 9.8016e-06 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.8336\n","Epoch 1349/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6969e-04 - accuracy: 1.0000\n","Epoch 1349: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6736e-04 - accuracy: 1.0000 - val_loss: 1.7573 - val_accuracy: 0.6730\n","Epoch 1350/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.9169e-04 - accuracy: 1.0000\n","Epoch 1350: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 8.8457e-04 - accuracy: 1.0000 - val_loss: 1.2691 - val_accuracy: 0.6966\n","Epoch 1351/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3176e-04 - accuracy: 1.0000\n","Epoch 1351: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 49ms/step - loss: 1.3176e-04 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.7437\n","Epoch 1352/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7546e-05 - accuracy: 1.0000\n","Epoch 1352: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.7546e-05 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.7909\n","Epoch 1353/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.7858e-05 - accuracy: 1.0000\n","Epoch 1353: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.7223e-05 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.7850\n","Epoch 1354/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5814e-05 - accuracy: 1.0000\n","Epoch 1354: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7128e-05 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.7791\n","Epoch 1355/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5311e-05 - accuracy: 1.0000\n","Epoch 1355: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5311e-05 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.7894\n","Epoch 1356/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.0649e-05 - accuracy: 1.0000\n","Epoch 1356: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.0649e-05 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.7968\n","Epoch 1357/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0946e-05 - accuracy: 1.0000\n","Epoch 1357: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0888e-05 - accuracy: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.8115\n","Epoch 1358/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5621e-05 - accuracy: 1.0000\n","Epoch 1358: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5621e-05 - accuracy: 1.0000 - val_loss: 0.5599 - val_accuracy: 0.8144\n","Epoch 1359/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9967e-05 - accuracy: 1.0000\n","Epoch 1359: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9798e-05 - accuracy: 1.0000 - val_loss: 0.5613 - val_accuracy: 0.8130\n","Epoch 1360/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0149e-05 - accuracy: 1.0000\n","Epoch 1360: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0149e-05 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.8174\n","Epoch 1361/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.9727e-06 - accuracy: 1.0000\n","Epoch 1361: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 9.9727e-06 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.8233\n","Epoch 1362/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5592e-05 - accuracy: 1.0000\n","Epoch 1362: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5592e-05 - accuracy: 1.0000 - val_loss: 0.5428 - val_accuracy: 0.8159\n","Epoch 1363/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.4711e-06 - accuracy: 1.0000\n","Epoch 1363: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4472e-06 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8115\n","Epoch 1364/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1226e-05 - accuracy: 1.0000\n","Epoch 1364: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1150e-05 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.8233\n","Epoch 1365/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.1299e-06 - accuracy: 1.0000\n","Epoch 1365: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4405e-06 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.8203\n","Epoch 1366/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.8352e-06 - accuracy: 1.0000\n","Epoch 1366: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.7920e-06 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.8174\n","Epoch 1367/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8420e-05 - accuracy: 1.0000\n","Epoch 1367: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.8294e-05 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.8321\n","Epoch 1368/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1046e-05 - accuracy: 1.0000\n","Epoch 1368: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1041e-05 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.8395\n","Epoch 1369/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3686e-05 - accuracy: 1.0000\n","Epoch 1369: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3606e-05 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8351\n","Epoch 1370/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1797e-05 - accuracy: 1.0000\n","Epoch 1370: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1797e-05 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.8380\n","Epoch 1371/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.8085e-06 - accuracy: 1.0000\n","Epoch 1371: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 8.7387e-06 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.8336\n","Epoch 1372/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.3512e-05 - accuracy: 1.0000\n","Epoch 1372: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3512e-05 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.7717\n","Epoch 1373/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4956e-05 - accuracy: 1.0000\n","Epoch 1373: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4770e-05 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.8130\n","Epoch 1374/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.5723e-06 - accuracy: 1.0000\n","Epoch 1374: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.5723e-06 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.8454\n","Epoch 1375/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.4351e-06 - accuracy: 1.0000\n","Epoch 1375: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 8.3590e-06 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8542\n","Epoch 1376/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.7006e-06 - accuracy: 1.0000\n","Epoch 1376: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.7006e-06 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.8557\n","Epoch 1377/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4382e-05 - accuracy: 1.0000\n","Epoch 1377: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4382e-05 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.8689\n","Epoch 1378/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.9227e-06 - accuracy: 1.0000\n","Epoch 1378: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.9227e-06 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.8704\n","Epoch 1379/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5908e-05 - accuracy: 1.0000\n","Epoch 1379: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5502e-05 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.8336\n","Epoch 1380/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3171e-05 - accuracy: 1.0000\n","Epoch 1380: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3058e-05 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8748\n","Epoch 1381/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3242e-05 - accuracy: 1.0000\n","Epoch 1381: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3242e-05 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.8409\n","Epoch 1382/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.3381e-06 - accuracy: 1.0000\n","Epoch 1382: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 8.2796e-06 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.8395\n","Epoch 1383/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6024e-06 - accuracy: 1.0000\n","Epoch 1383: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.5993e-06 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.8395\n","Epoch 1384/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9821e-06 - accuracy: 1.0000\n","Epoch 1384: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.9324e-06 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8527\n","Epoch 1385/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9139e-05 - accuracy: 1.0000\n","Epoch 1385: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9139e-05 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8513\n","Epoch 1386/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.7035e-06 - accuracy: 1.0000\n","Epoch 1386: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.7035e-06 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.8645\n","Epoch 1387/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.7010e-06 - accuracy: 1.0000\n","Epoch 1387: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.6534e-06 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.8616\n","Epoch 1388/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3707e-06 - accuracy: 1.0000\n","Epoch 1388: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 49ms/step - loss: 3.3547e-06 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8630\n","Epoch 1389/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6609e-06 - accuracy: 1.0000\n","Epoch 1389: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.6609e-06 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.8704\n","Epoch 1390/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.5791e-06 - accuracy: 1.0000\n","Epoch 1390: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 6s 49ms/step - loss: 6.5791e-06 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.8822\n","Epoch 1391/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0722e-06 - accuracy: 1.0000\n","Epoch 1391: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0562e-06 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.8748\n","Epoch 1392/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1042e-06 - accuracy: 1.0000\n","Epoch 1392: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1264e-06 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.8733\n","Epoch 1393/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0093e-05 - accuracy: 1.0000\n","Epoch 1393: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0093e-05 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.8542\n","Epoch 1394/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.5060e-06 - accuracy: 1.0000\n","Epoch 1394: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 8.4336e-06 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.8586\n","Epoch 1395/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3110e-06 - accuracy: 1.0000\n","Epoch 1395: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2935e-06 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.8601\n","Epoch 1396/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4572e-06 - accuracy: 1.0000\n","Epoch 1396: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4572e-06 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8586\n","Epoch 1397/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4993e-06 - accuracy: 1.0000\n","Epoch 1397: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4774e-06 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.8498\n","Epoch 1398/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2104e-06 - accuracy: 1.0000\n","Epoch 1398: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1913e-06 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.8542\n","Epoch 1399/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1712e-06 - accuracy: 1.0000\n","Epoch 1399: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1643e-06 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8571\n","Epoch 1400/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1738e-06 - accuracy: 1.0000\n","Epoch 1400: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1657e-06 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.8630\n","Epoch 1401/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4235e-06 - accuracy: 1.0000\n","Epoch 1401: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3764e-06 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.8601\n","Epoch 1402/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994\n","Epoch 1402: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.7801 - val_accuracy: 0.6406\n","Epoch 1403/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.1777e-04 - accuracy: 1.0000\n","Epoch 1403: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 8.1027e-04 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.8513\n","Epoch 1404/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3317e-04 - accuracy: 1.0000\n","Epoch 1404: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3196e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8424\n","Epoch 1405/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4393e-05 - accuracy: 1.0000\n","Epoch 1405: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3921e-05 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8247\n","Epoch 1406/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7128e-05 - accuracy: 1.0000\n","Epoch 1406: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7393e-05 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8233\n","Epoch 1407/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.7678e-05 - accuracy: 1.0000\n","Epoch 1407: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.7678e-05 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8218\n","Epoch 1408/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.0592e-05 - accuracy: 1.0000\n","Epoch 1408: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.0592e-05 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.8409\n","Epoch 1409/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4368e-05 - accuracy: 1.0000\n","Epoch 1409: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4065e-05 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8247\n","Epoch 1410/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6082e-05 - accuracy: 1.0000\n","Epoch 1410: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 49ms/step - loss: 3.1454e-05 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 0.8351\n","Epoch 1411/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9201e-04 - accuracy: 1.0000\n","Epoch 1411: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9201e-04 - accuracy: 1.0000 - val_loss: 1.5948 - val_accuracy: 0.6568\n","Epoch 1412/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3697e-04 - accuracy: 1.0000\n","Epoch 1412: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3579e-04 - accuracy: 1.0000 - val_loss: 0.8972 - val_accuracy: 0.8012\n","Epoch 1413/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2162e-05 - accuracy: 1.0000\n","Epoch 1413: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.2162e-05 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.8189\n","Epoch 1414/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.6131e-05 - accuracy: 1.0000\n","Epoch 1414: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.5822e-05 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 0.8306\n","Epoch 1415/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9991\n","Epoch 1415: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.8721 - val_accuracy: 0.6377\n","Epoch 1416/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n","Epoch 1416: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 3.8424 - val_accuracy: 0.5199\n","Epoch 1417/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6900e-04 - accuracy: 1.0000\n","Epoch 1417: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6657e-04 - accuracy: 1.0000 - val_loss: 1.3591 - val_accuracy: 0.7231\n","Epoch 1418/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4099e-04 - accuracy: 1.0000\n","Epoch 1418: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3972e-04 - accuracy: 1.0000 - val_loss: 0.8258 - val_accuracy: 0.7835\n","Epoch 1419/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.8664e-04 - accuracy: 1.0000\n","Epoch 1419: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8664e-04 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.8130\n","Epoch 1420/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0704e-05 - accuracy: 1.0000\n","Epoch 1420: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.0520e-05 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.8203\n","Epoch 1421/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6868e-05 - accuracy: 1.0000\n","Epoch 1421: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6868e-05 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 0.8247\n","Epoch 1422/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.5192e-05 - accuracy: 1.0000\n","Epoch 1422: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4898e-05 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.8218\n","Epoch 1423/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0057e-04 - accuracy: 1.0000\n","Epoch 1423: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0057e-04 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 0.8130\n","Epoch 1424/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0764e-04 - accuracy: 1.0000\n","Epoch 1424: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0764e-04 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.8203\n","Epoch 1425/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.3938e-05 - accuracy: 1.0000\n","Epoch 1425: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3938e-05 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.8277\n","Epoch 1426/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9500e-05 - accuracy: 1.0000\n","Epoch 1426: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9275e-05 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.8321\n","Epoch 1427/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9510e-05 - accuracy: 1.0000\n","Epoch 1427: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.0659e-05 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8306\n","Epoch 1428/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3515e-05 - accuracy: 1.0000\n","Epoch 1428: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3341e-05 - accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.8321\n","Epoch 1429/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2123e-05 - accuracy: 1.0000\n","Epoch 1429: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2123e-05 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.8380\n","Epoch 1430/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.1857e-05 - accuracy: 1.0000\n","Epoch 1430: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.1417e-05 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.8424\n","Epoch 1431/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5259e-04 - accuracy: 1.0000\n","Epoch 1431: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5189e-04 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.8247\n","Epoch 1432/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2733e-05 - accuracy: 1.0000\n","Epoch 1432: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2733e-05 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.8498\n","Epoch 1433/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9048e-05 - accuracy: 1.0000\n","Epoch 1433: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.8679e-05 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8351\n","Epoch 1434/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2382e-05 - accuracy: 1.0000\n","Epoch 1434: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.3870e-05 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.8292\n","Epoch 1435/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.4666e-05 - accuracy: 1.0000\n","Epoch 1435: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4277e-05 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.8424\n","Epoch 1436/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5851e-05 - accuracy: 1.0000\n","Epoch 1436: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5636e-05 - accuracy: 1.0000 - val_loss: 0.5675 - val_accuracy: 0.8351\n","Epoch 1437/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9787e-05 - accuracy: 1.0000\n","Epoch 1437: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9787e-05 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.8424\n","Epoch 1438/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.2561e-05 - accuracy: 1.0000\n","Epoch 1438: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2203e-05 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.8527\n","Epoch 1439/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6274e-05 - accuracy: 1.0000\n","Epoch 1439: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5923e-05 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.8336\n","Epoch 1440/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.8441e-05 - accuracy: 1.0000\n","Epoch 1440: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8441e-05 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.8454\n","Epoch 1441/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.8289e-06 - accuracy: 1.0000\n","Epoch 1441: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 7.8289e-06 - accuracy: 1.0000 - val_loss: 0.5880 - val_accuracy: 0.8409\n","Epoch 1442/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.8915e-06 - accuracy: 1.0000\n","Epoch 1442: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 9.8421e-06 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.8454\n","Epoch 1443/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.8123e-06 - accuracy: 1.0000\n","Epoch 1443: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.7730e-06 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.8439\n","Epoch 1444/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2508e-05 - accuracy: 1.0000\n","Epoch 1444: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2450e-05 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.8439\n","Epoch 1445/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6536e-05 - accuracy: 1.0000\n","Epoch 1445: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6401e-05 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.8424\n","Epoch 1446/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.5625e-06 - accuracy: 1.0000\n","Epoch 1446: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.5224e-06 - accuracy: 1.0000 - val_loss: 0.5641 - val_accuracy: 0.8454\n","Epoch 1447/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.8144e-06 - accuracy: 1.0000\n","Epoch 1447: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 9.8144e-06 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.8468\n","Epoch 1448/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.4743e-06 - accuracy: 1.0000\n","Epoch 1448: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.4743e-06 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.8498\n","Epoch 1449/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.3251e-06 - accuracy: 1.0000\n","Epoch 1449: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 7.2895e-06 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.8527\n","Epoch 1450/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.9925e-06 - accuracy: 1.0000\n","Epoch 1450: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.9439e-06 - accuracy: 1.0000 - val_loss: 0.5445 - val_accuracy: 0.8557\n","Epoch 1451/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.7277e-06 - accuracy: 1.0000\n","Epoch 1451: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.7277e-06 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8571\n","Epoch 1452/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.3990e-06 - accuracy: 1.0000\n","Epoch 1452: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3990e-06 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.8571\n","Epoch 1453/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.6618e-06 - accuracy: 1.0000\n","Epoch 1453: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.6618e-06 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.8498\n","Epoch 1454/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.4989e-06 - accuracy: 1.0000\n","Epoch 1454: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.4989e-06 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.8542\n","Epoch 1455/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.6139e-06 - accuracy: 1.0000\n","Epoch 1455: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.6139e-06 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.8527\n","Epoch 1456/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0499e-05 - accuracy: 1.0000\n","Epoch 1456: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0499e-05 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.8527\n","Epoch 1457/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.4429e-06 - accuracy: 1.0000\n","Epoch 1457: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.4643e-06 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8571\n","Epoch 1458/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.3794e-06 - accuracy: 1.0000\n","Epoch 1458: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.3443e-06 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8527\n","Epoch 1459/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5151e-06 - accuracy: 1.0000\n","Epoch 1459: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5078e-06 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.8542\n","Epoch 1460/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5885e-05 - accuracy: 1.0000\n","Epoch 1460: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5764e-05 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.8571\n","Epoch 1461/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2341e-06 - accuracy: 1.0000\n","Epoch 1461: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2341e-06 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.8557\n","Epoch 1462/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5181e-06 - accuracy: 1.0000\n","Epoch 1462: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.4823e-06 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.8557\n","Epoch 1463/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.3843e-06 - accuracy: 1.0000\n","Epoch 1463: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 7.3270e-06 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.8527\n","Epoch 1464/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0357e-06 - accuracy: 1.0000\n","Epoch 1464: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0357e-06 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.8542\n","Epoch 1465/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.3430e-06 - accuracy: 1.0000\n","Epoch 1465: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.2949e-06 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.8527\n","Epoch 1466/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0484e-06 - accuracy: 1.0000\n","Epoch 1466: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0884e-06 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.8601\n","Epoch 1467/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0699e-06 - accuracy: 1.0000\n","Epoch 1467: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0382e-06 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8527\n","Epoch 1468/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.5175e-06 - accuracy: 1.0000\n","Epoch 1468: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.5175e-06 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8571\n","Epoch 1469/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1442e-06 - accuracy: 1.0000\n","Epoch 1469: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1308e-06 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.8630\n","Epoch 1470/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8261e-06 - accuracy: 1.0000\n","Epoch 1470: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8355e-06 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.8601\n","Epoch 1471/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.3936e-06 - accuracy: 1.0000\n","Epoch 1471: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.3592e-06 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.8630\n","Epoch 1472/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9846e-06 - accuracy: 1.0000\n","Epoch 1472: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.0056e-06 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.8645\n","Epoch 1473/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6734e-05 - accuracy: 1.0000\n","Epoch 1473: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.6734e-05 - accuracy: 1.0000 - val_loss: 0.5540 - val_accuracy: 0.8424\n","Epoch 1474/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2918e-06 - accuracy: 1.0000\n","Epoch 1474: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.2456e-06 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.8336\n","Epoch 1475/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4021e-06 - accuracy: 1.0000\n","Epoch 1475: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.4033e-06 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.8336\n","Epoch 1476/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.3552e-06 - accuracy: 1.0000\n","Epoch 1476: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3552e-06 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.8365\n","Epoch 1477/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9943e-06 - accuracy: 1.0000\n","Epoch 1477: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9884e-06 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8321\n","Epoch 1478/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4312e-06 - accuracy: 1.0000\n","Epoch 1478: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.4312e-06 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8380\n","Epoch 1479/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5352e-06 - accuracy: 1.0000\n","Epoch 1479: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.6037e-06 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8336\n","Epoch 1480/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7263e-06 - accuracy: 1.0000\n","Epoch 1480: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7263e-06 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.8380\n","Epoch 1481/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1800e-06 - accuracy: 1.0000\n","Epoch 1481: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1800e-06 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.8395\n","Epoch 1482/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5985e-06 - accuracy: 1.0000\n","Epoch 1482: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5985e-06 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.8468\n","Epoch 1483/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2667e-06 - accuracy: 1.0000\n","Epoch 1483: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2595e-06 - accuracy: 1.0000 - val_loss: 0.5123 - val_accuracy: 0.8498\n","Epoch 1484/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9714e-06 - accuracy: 1.0000\n","Epoch 1484: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9558e-06 - accuracy: 1.0000 - val_loss: 0.5235 - val_accuracy: 0.8395\n","Epoch 1485/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0235e-06 - accuracy: 1.0000\n","Epoch 1485: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0235e-06 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.8542\n","Epoch 1486/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3392e-06 - accuracy: 1.0000\n","Epoch 1486: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3928e-06 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8557\n","Epoch 1487/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.8284e-06 - accuracy: 1.0000\n","Epoch 1487: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 49ms/step - loss: 6.8284e-06 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.8645\n","Epoch 1488/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5814e-06 - accuracy: 1.0000\n","Epoch 1488: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5814e-06 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.8763\n","Epoch 1489/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5689e-06 - accuracy: 1.0000\n","Epoch 1489: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5689e-06 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8748\n","Epoch 1490/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2244e-06 - accuracy: 1.0000\n","Epoch 1490: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 3.2244e-06 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.8675\n","Epoch 1491/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0192e-06 - accuracy: 1.0000\n","Epoch 1491: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0130e-06 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.8733\n","Epoch 1492/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4316e-06 - accuracy: 1.0000\n","Epoch 1492: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4372e-06 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8778\n","Epoch 1493/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8749e-06 - accuracy: 1.0000\n","Epoch 1493: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8765e-06 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8837\n","Epoch 1494/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0760e-06 - accuracy: 1.0000\n","Epoch 1494: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0891e-06 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8837\n","Epoch 1495/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6713e-06 - accuracy: 1.0000\n","Epoch 1495: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6862e-06 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8704\n","Epoch 1496/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6992e-07 - accuracy: 1.0000\n","Epoch 1496: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 6.6496e-07 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8733\n","Epoch 1497/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0581e-06 - accuracy: 1.0000\n","Epoch 1497: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0495e-06 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8719\n","Epoch 1498/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1973e-06 - accuracy: 1.0000\n","Epoch 1498: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1973e-06 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.8704\n","Epoch 1499/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.1329e-07 - accuracy: 1.0000\n","Epoch 1499: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.1329e-07 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.8704\n","Epoch 1500/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2870e-06 - accuracy: 1.0000\n","Epoch 1500: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2683e-06 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.8468\n","Epoch 1501/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9427e-06 - accuracy: 1.0000\n","Epoch 1501: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9175e-06 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8542\n","Epoch 1502/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0010e-06 - accuracy: 1.0000\n","Epoch 1502: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0010e-06 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.8483\n","Epoch 1503/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6839e-06 - accuracy: 1.0000\n","Epoch 1503: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6709e-06 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.8483\n","Epoch 1504/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.5552e-07 - accuracy: 1.0000\n","Epoch 1504: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 8.5552e-07 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.8557\n","Epoch 1505/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2899e-06 - accuracy: 1.0000\n","Epoch 1505: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2899e-06 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.8409\n","Epoch 1506/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.4310e-05 - accuracy: 1.0000\n","Epoch 1506: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 9.3773e-05 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.6068\n","Epoch 1507/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9980\n","Epoch 1507: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 4.4237 - val_accuracy: 0.4507\n","Epoch 1508/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n","Epoch 1508: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 1.4744 - val_accuracy: 0.6613\n","Epoch 1509/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 1509: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.7274 - val_accuracy: 0.7879\n","Epoch 1510/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 1510: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.3372 - val_accuracy: 0.8807\n","Epoch 1511/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.3329e-05 - accuracy: 1.0000\n","Epoch 1511: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3329e-05 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.8439\n","Epoch 1512/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.8844e-04 - accuracy: 1.0000\n","Epoch 1512: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.8844e-04 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.7555\n","Epoch 1513/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5949e-05 - accuracy: 1.0000\n","Epoch 1513: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5576e-05 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8071\n","Epoch 1514/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6847e-05 - accuracy: 1.0000\n","Epoch 1514: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6847e-05 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.8189\n","Epoch 1515/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0022e-05 - accuracy: 1.0000\n","Epoch 1515: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0022e-05 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8233\n","Epoch 1516/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2446e-05 - accuracy: 1.0000\n","Epoch 1516: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2446e-05 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8292\n","Epoch 1517/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1397e-04 - accuracy: 1.0000\n","Epoch 1517: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1397e-04 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.8351\n","Epoch 1518/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9067e-05 - accuracy: 1.0000\n","Epoch 1518: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8830e-05 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.8336\n","Epoch 1519/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0894e-05 - accuracy: 1.0000\n","Epoch 1519: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0527e-05 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8439\n","Epoch 1520/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.0436e-05 - accuracy: 1.0000\n","Epoch 1520: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0436e-05 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.8424\n","Epoch 1521/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5401e-05 - accuracy: 1.0000\n","Epoch 1521: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5401e-05 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.8468\n","Epoch 1522/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6045e-05 - accuracy: 1.0000\n","Epoch 1522: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5867e-05 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.8424\n","Epoch 1523/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8612e-05 - accuracy: 1.0000\n","Epoch 1523: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 8.8612e-05 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.8395\n","Epoch 1524/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.1592e-05 - accuracy: 1.0000\n","Epoch 1524: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.1120e-05 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.8409\n","Epoch 1525/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9692e-05 - accuracy: 1.0000\n","Epoch 1525: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9683e-05 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.8454\n","Epoch 1526/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9954e-05 - accuracy: 1.0000\n","Epoch 1526: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9794e-05 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.8454\n","Epoch 1527/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9637e-04 - accuracy: 0.9997\n","Epoch 1527: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9180e-04 - accuracy: 0.9997 - val_loss: 0.5857 - val_accuracy: 0.8159\n","Epoch 1528/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7889e-04 - accuracy: 1.0000\n","Epoch 1528: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7889e-04 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7290\n","Epoch 1529/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.6555e-05 - accuracy: 1.0000\n","Epoch 1529: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.6301e-05 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.8071\n","Epoch 1530/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.0261e-05 - accuracy: 1.0000\n","Epoch 1530: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.9877e-05 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.8262\n","Epoch 1531/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9111e-05 - accuracy: 1.0000\n","Epoch 1531: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9111e-05 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.8424\n","Epoch 1532/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.1039e-05 - accuracy: 1.0000\n","Epoch 1532: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.0574e-05 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8439\n","Epoch 1533/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1021e-05 - accuracy: 1.0000\n","Epoch 1533: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0659e-05 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8454\n","Epoch 1534/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5549e-05 - accuracy: 1.0000\n","Epoch 1534: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5652e-05 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.8454\n","Epoch 1535/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8252e-04 - accuracy: 1.0000\n","Epoch 1535: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7992e-04 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 0.8012\n","Epoch 1536/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3981e-05 - accuracy: 1.0000\n","Epoch 1536: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3774e-05 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8513\n","Epoch 1537/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.7619e-05 - accuracy: 1.0000\n","Epoch 1537: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 9.6771e-05 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.8483\n","Epoch 1538/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2166e-05 - accuracy: 1.0000\n","Epoch 1538: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2166e-05 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8513\n","Epoch 1539/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7938e-05 - accuracy: 1.0000\n","Epoch 1539: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7774e-05 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.8498\n","Epoch 1540/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.4488e-06 - accuracy: 1.0000\n","Epoch 1540: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 9.4488e-06 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.8498\n","Epoch 1541/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7939e-04 - accuracy: 0.9997\n","Epoch 1541: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7939e-04 - accuracy: 0.9997 - val_loss: 0.8418 - val_accuracy: 0.7658\n","Epoch 1542/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.0343e-04 - accuracy: 0.9997\n","Epoch 1542: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.0343e-04 - accuracy: 0.9997 - val_loss: 0.4743 - val_accuracy: 0.8365\n","Epoch 1543/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2198e-04 - accuracy: 1.0000\n","Epoch 1543: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2097e-04 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.8292\n","Epoch 1544/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4711e-05 - accuracy: 1.0000\n","Epoch 1544: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4718e-05 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.8292\n","Epoch 1545/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.5194e-05 - accuracy: 1.0000\n","Epoch 1545: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 49ms/step - loss: 3.4936e-05 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.8365\n","Epoch 1546/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3478e-04 - accuracy: 1.0000\n","Epoch 1546: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3354e-04 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8586\n","Epoch 1547/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4397e-05 - accuracy: 1.0000\n","Epoch 1547: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3945e-05 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.8262\n","Epoch 1548/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2929e-05 - accuracy: 1.0000\n","Epoch 1548: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2827e-05 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.8439\n","Epoch 1549/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.5985e-06 - accuracy: 1.0000\n","Epoch 1549: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 9.5985e-06 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.8498\n","Epoch 1550/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6829e-05 - accuracy: 1.0000\n","Epoch 1550: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6829e-05 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.8675\n","Epoch 1551/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.1771e-04 - accuracy: 0.9997\n","Epoch 1551: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 5.1771e-04 - accuracy: 0.9997 - val_loss: 1.0105 - val_accuracy: 0.6996\n","Epoch 1552/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9991\n","Epoch 1552: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 2.3333 - val_accuracy: 0.6303\n","Epoch 1553/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6565e-04 - accuracy: 1.0000\n","Epoch 1553: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6328e-04 - accuracy: 1.0000 - val_loss: 0.9332 - val_accuracy: 0.7496\n","Epoch 1554/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.9915e-04 - accuracy: 0.9997\n","Epoch 1554: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 7.9915e-04 - accuracy: 0.9997 - val_loss: 0.9474 - val_accuracy: 0.7467\n","Epoch 1555/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n","Epoch 1555: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.0533 - val_accuracy: 0.7290\n","Epoch 1556/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1534e-04 - accuracy: 1.0000\n","Epoch 1556: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1159e-04 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.7599\n","Epoch 1557/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6803e-04 - accuracy: 0.9997\n","Epoch 1557: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 4.6410e-04 - accuracy: 0.9997 - val_loss: 0.8985 - val_accuracy: 0.7496\n","Epoch 1558/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4078e-04 - accuracy: 1.0000\n","Epoch 1558: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.4078e-04 - accuracy: 1.0000 - val_loss: 1.0697 - val_accuracy: 0.7069\n","Epoch 1559/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.6864e-05 - accuracy: 1.0000\n","Epoch 1559: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.6864e-05 - accuracy: 1.0000 - val_loss: 0.5954 - val_accuracy: 0.7968\n","Epoch 1560/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.4268e-05 - accuracy: 1.0000\n","Epoch 1560: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4268e-05 - accuracy: 1.0000 - val_loss: 0.5393 - val_accuracy: 0.8085\n","Epoch 1561/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0357e-04 - accuracy: 1.0000\n","Epoch 1561: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0357e-04 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8395\n","Epoch 1562/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8251e-05 - accuracy: 1.0000\n","Epoch 1562: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.8039e-05 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8321\n","Epoch 1563/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5822e-05 - accuracy: 1.0000\n","Epoch 1563: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5822e-05 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.8262\n","Epoch 1564/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9931e-05 - accuracy: 1.0000\n","Epoch 1564: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.9428e-05 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.8321\n","Epoch 1565/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2714e-05 - accuracy: 1.0000\n","Epoch 1565: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2714e-05 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.8380\n","Epoch 1566/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1818e-05 - accuracy: 1.0000\n","Epoch 1566: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1818e-05 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.8395\n","Epoch 1567/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2690e-04 - accuracy: 1.0000\n","Epoch 1567: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2484e-04 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 0.7850\n","Epoch 1568/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.5679e-05 - accuracy: 1.0000\n","Epoch 1568: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 5.5212e-05 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.8409\n","Epoch 1569/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0519e-05 - accuracy: 1.0000\n","Epoch 1569: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0519e-05 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.8542\n","Epoch 1570/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5101e-05 - accuracy: 1.0000\n","Epoch 1570: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4990e-05 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.8586\n","Epoch 1571/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.8347e-05 - accuracy: 1.0000\n","Epoch 1571: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7996e-05 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.8601\n","Epoch 1572/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2840e-05 - accuracy: 1.0000\n","Epoch 1572: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2840e-05 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.8616\n","Epoch 1573/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9085e-05 - accuracy: 1.0000\n","Epoch 1573: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9085e-05 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.8542\n","Epoch 1574/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1787e-04 - accuracy: 1.0000\n","Epoch 1574: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1595e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.8513\n","Epoch 1575/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9371e-05 - accuracy: 1.0000\n","Epoch 1575: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9205e-05 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8557\n","Epoch 1576/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6315e-05 - accuracy: 1.0000\n","Epoch 1576: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6315e-05 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8557\n","Epoch 1577/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.6524e-05 - accuracy: 1.0000\n","Epoch 1577: val_accuracy did not improve from 0.88660\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6524e-05 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.8601\n","Epoch 1578/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2301e-05 - accuracy: 1.0000\n","Epoch 1578: val_accuracy improved from 0.88660 to 0.89249, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 10s 88ms/step - loss: 6.2301e-05 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.8925\n","Epoch 1579/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1945e-05 - accuracy: 1.0000\n","Epoch 1579: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1856e-05 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8778\n","Epoch 1580/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.9307e-06 - accuracy: 1.0000\n","Epoch 1580: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.9307e-06 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.8748\n","Epoch 1581/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0184e-05 - accuracy: 1.0000\n","Epoch 1581: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 1.0144e-05 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.8630\n","Epoch 1582/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2319e-05 - accuracy: 1.0000\n","Epoch 1582: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2319e-05 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.8630\n","Epoch 1583/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.4001e-06 - accuracy: 1.0000\n","Epoch 1583: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.3248e-06 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.8660\n","Epoch 1584/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7934e-05 - accuracy: 1.0000\n","Epoch 1584: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7934e-05 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8380\n","Epoch 1585/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4840e-05 - accuracy: 1.0000\n","Epoch 1585: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4840e-05 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.8660\n","Epoch 1586/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.8487e-06 - accuracy: 1.0000\n","Epoch 1586: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.8487e-06 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.8763\n","Epoch 1587/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.5775e-06 - accuracy: 1.0000\n","Epoch 1587: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.5430e-06 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.8733\n","Epoch 1588/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1196e-05 - accuracy: 1.0000\n","Epoch 1588: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1196e-05 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.8881\n","Epoch 1589/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3317e-05 - accuracy: 1.0000\n","Epoch 1589: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3317e-05 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.8822\n","Epoch 1590/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1447e-05 - accuracy: 1.0000\n","Epoch 1590: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1346e-05 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.8837\n","Epoch 1591/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0576e-06 - accuracy: 1.0000\n","Epoch 1591: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0455e-06 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.8822\n","Epoch 1592/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1897e-05 - accuracy: 1.0000\n","Epoch 1592: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1790e-05 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.8822\n","Epoch 1593/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6743e-05 - accuracy: 1.0000\n","Epoch 1593: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6601e-05 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.8925\n","Epoch 1594/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3288e-05 - accuracy: 1.0000\n","Epoch 1594: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3288e-05 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.8792\n","Epoch 1595/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2684e-06 - accuracy: 1.0000\n","Epoch 1595: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2120e-06 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.8719\n","Epoch 1596/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9452e-06 - accuracy: 1.0000\n","Epoch 1596: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9452e-06 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.8733\n","Epoch 1597/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.3987e-06 - accuracy: 1.0000\n","Epoch 1597: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.3987e-06 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.8748\n","Epoch 1598/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2686e-06 - accuracy: 1.0000\n","Epoch 1598: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2103e-06 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.8733\n","Epoch 1599/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7677e-06 - accuracy: 1.0000\n","Epoch 1599: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7554e-06 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.8733\n","Epoch 1600/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.9227e-06 - accuracy: 1.0000\n","Epoch 1600: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.9227e-06 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.8704\n","Epoch 1601/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4655e-06 - accuracy: 1.0000\n","Epoch 1601: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4511e-06 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.8733\n","Epoch 1602/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.0978e-06 - accuracy: 1.0000\n","Epoch 1602: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0978e-06 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.8689\n","Epoch 1603/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.0972e-06 - accuracy: 1.0000\n","Epoch 1603: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.0263e-06 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.8748\n","Epoch 1604/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0347e-06 - accuracy: 1.0000\n","Epoch 1604: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0027e-06 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.8689\n","Epoch 1605/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.0697e-06 - accuracy: 1.0000\n","Epoch 1605: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.0697e-06 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.8704\n","Epoch 1606/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8505e-05 - accuracy: 1.0000\n","Epoch 1606: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8338e-05 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8822\n","Epoch 1607/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9795e-06 - accuracy: 1.0000\n","Epoch 1607: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9630e-06 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.8719\n","Epoch 1608/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6830e-05 - accuracy: 1.0000\n","Epoch 1608: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6830e-05 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8056\n","Epoch 1609/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9991\n","Epoch 1609: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 5.5890 - val_accuracy: 0.4374\n","Epoch 1610/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9991\n","Epoch 1610: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 1.9997 - val_accuracy: 0.5582\n","Epoch 1611/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4140e-04 - accuracy: 0.9997\n","Epoch 1611: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.4140e-04 - accuracy: 0.9997 - val_loss: 0.8750 - val_accuracy: 0.7953\n","Epoch 1612/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2724e-05 - accuracy: 1.0000\n","Epoch 1612: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.2595e-05 - accuracy: 1.0000 - val_loss: 0.8340 - val_accuracy: 0.7997\n","Epoch 1613/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.4622e-05 - accuracy: 1.0000\n","Epoch 1613: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.4622e-05 - accuracy: 1.0000 - val_loss: 0.8173 - val_accuracy: 0.7953\n","Epoch 1614/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1689e-04 - accuracy: 1.0000\n","Epoch 1614: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1689e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8085\n","Epoch 1615/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1601e-05 - accuracy: 1.0000\n","Epoch 1615: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1601e-05 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8056\n","Epoch 1616/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.2054e-05 - accuracy: 1.0000\n","Epoch 1616: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.2054e-05 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8144\n","Epoch 1617/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.3030e-05 - accuracy: 1.0000\n","Epoch 1617: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.3030e-05 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8085\n","Epoch 1618/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9960e-05 - accuracy: 1.0000\n","Epoch 1618: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9960e-05 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.8100\n","Epoch 1619/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8363e-05 - accuracy: 1.0000\n","Epoch 1619: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8131e-05 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8159\n","Epoch 1620/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6027e-05 - accuracy: 1.0000\n","Epoch 1620: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5800e-05 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8159\n","Epoch 1621/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8527e-05 - accuracy: 1.0000\n","Epoch 1621: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8382e-05 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8144\n","Epoch 1622/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2164e-04 - accuracy: 1.0000\n","Epoch 1622: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1960e-04 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.7923\n","Epoch 1623/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.0865e-05 - accuracy: 1.0000\n","Epoch 1623: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.0128e-05 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.8277\n","Epoch 1624/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2513e-05 - accuracy: 1.0000\n","Epoch 1624: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2521e-05 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.8351\n","Epoch 1625/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.6643e-05 - accuracy: 1.0000\n","Epoch 1625: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6643e-05 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.8262\n","Epoch 1626/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9948e-05 - accuracy: 1.0000\n","Epoch 1626: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0101e-05 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.8292\n","Epoch 1627/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1489e-05 - accuracy: 1.0000\n","Epoch 1627: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1489e-05 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8306\n","Epoch 1628/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.7641e-05 - accuracy: 1.0000\n","Epoch 1628: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.7230e-05 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.8247\n","Epoch 1629/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2830e-05 - accuracy: 1.0000\n","Epoch 1629: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2830e-05 - accuracy: 1.0000 - val_loss: 0.6453 - val_accuracy: 0.8218\n","Epoch 1630/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4064e-05 - accuracy: 1.0000\n","Epoch 1630: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3843e-05 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 0.8218\n","Epoch 1631/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1118e-05 - accuracy: 1.0000\n","Epoch 1631: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0778e-05 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8262\n","Epoch 1632/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0862e-05 - accuracy: 1.0000\n","Epoch 1632: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0703e-05 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8115\n","Epoch 1633/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1742e-05 - accuracy: 1.0000\n","Epoch 1633: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1645e-05 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 0.8189\n","Epoch 1634/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.1394e-06 - accuracy: 1.0000\n","Epoch 1634: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.1394e-06 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.8218\n","Epoch 1635/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9962e-06 - accuracy: 1.0000\n","Epoch 1635: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9662e-06 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.8233\n","Epoch 1636/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7761e-05 - accuracy: 1.0000\n","Epoch 1636: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7606e-05 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.8292\n","Epoch 1637/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.0363e-06 - accuracy: 1.0000\n","Epoch 1637: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.1104e-06 - accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.8351\n","Epoch 1638/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.9050e-06 - accuracy: 1.0000\n","Epoch 1638: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9050e-06 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.8395\n","Epoch 1639/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.5311e-06 - accuracy: 1.0000\n","Epoch 1639: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.4607e-06 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8454\n","Epoch 1640/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2943e-06 - accuracy: 1.0000\n","Epoch 1640: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.2943e-06 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.8409\n","Epoch 1641/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.4958e-06 - accuracy: 1.0000\n","Epoch 1641: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.4590e-06 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.8395\n","Epoch 1642/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.7648e-06 - accuracy: 1.0000\n","Epoch 1642: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.7648e-06 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8380\n","Epoch 1643/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.0093e-06 - accuracy: 1.0000\n","Epoch 1643: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9704e-06 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8351\n","Epoch 1644/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.0060e-05 - accuracy: 1.0000\n","Epoch 1644: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9615e-05 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.8409\n","Epoch 1645/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4803e-05 - accuracy: 1.0000\n","Epoch 1645: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4708e-05 - accuracy: 1.0000 - val_loss: 0.5432 - val_accuracy: 0.8365\n","Epoch 1646/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5050e-05 - accuracy: 1.0000\n","Epoch 1646: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4823e-05 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8027\n","Epoch 1647/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.4732e-06 - accuracy: 1.0000\n","Epoch 1647: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.4552e-06 - accuracy: 1.0000 - val_loss: 0.5364 - val_accuracy: 0.8336\n","Epoch 1648/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.8741e-06 - accuracy: 1.0000\n","Epoch 1648: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.8305e-06 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.8468\n","Epoch 1649/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.1840e-06 - accuracy: 1.0000\n","Epoch 1649: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.1196e-06 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8513\n","Epoch 1650/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.1719e-06 - accuracy: 1.0000\n","Epoch 1650: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.1719e-06 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.8542\n","Epoch 1651/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9746e-06 - accuracy: 1.0000\n","Epoch 1651: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9390e-06 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8513\n","Epoch 1652/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1170e-05 - accuracy: 1.0000\n","Epoch 1652: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1170e-05 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.8527\n","Epoch 1653/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7096e-05 - accuracy: 1.0000\n","Epoch 1653: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7096e-05 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.8675\n","Epoch 1654/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.0961e-06 - accuracy: 1.0000\n","Epoch 1654: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.0417e-06 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8881\n","Epoch 1655/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0216e-05 - accuracy: 1.0000\n","Epoch 1655: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9945e-05 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.8527\n","Epoch 1656/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1550e-06 - accuracy: 1.0000\n","Epoch 1656: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.1654e-06 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.8498\n","Epoch 1657/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0995e-05 - accuracy: 1.0000\n","Epoch 1657: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0995e-05 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.8586\n","Epoch 1658/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.5858e-06 - accuracy: 1.0000\n","Epoch 1658: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.5858e-06 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8601\n","Epoch 1659/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.0554e-06 - accuracy: 1.0000\n","Epoch 1659: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.0332e-06 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8616\n","Epoch 1660/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.5063e-06 - accuracy: 1.0000\n","Epoch 1660: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.5063e-06 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8660\n","Epoch 1661/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5609e-06 - accuracy: 1.0000\n","Epoch 1661: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5462e-06 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8660\n","Epoch 1662/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2569e-06 - accuracy: 1.0000\n","Epoch 1662: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2552e-06 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.8645\n","Epoch 1663/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.7855e-06 - accuracy: 1.0000\n","Epoch 1663: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.7855e-06 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.8586\n","Epoch 1664/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.7539e-06 - accuracy: 1.0000\n","Epoch 1664: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.6994e-06 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.8660\n","Epoch 1665/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.6812e-06 - accuracy: 1.0000\n","Epoch 1665: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6812e-06 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8630\n","Epoch 1666/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1339e-05 - accuracy: 1.0000\n","Epoch 1666: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1235e-05 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.8542\n","Epoch 1667/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9223e-06 - accuracy: 1.0000\n","Epoch 1667: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.0349e-06 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.8542\n","Epoch 1668/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.7849e-06 - accuracy: 1.0000\n","Epoch 1668: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.7560e-06 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.8409\n","Epoch 1669/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2101e-06 - accuracy: 1.0000\n","Epoch 1669: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.1443e-06 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.8513\n","Epoch 1670/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6784e-06 - accuracy: 1.0000\n","Epoch 1670: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6784e-06 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8542\n","Epoch 1671/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2574e-06 - accuracy: 1.0000\n","Epoch 1671: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2574e-06 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.8513\n","Epoch 1672/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6999e-06 - accuracy: 1.0000\n","Epoch 1672: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7465e-06 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.8468\n","Epoch 1673/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5555e-06 - accuracy: 1.0000\n","Epoch 1673: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5328e-06 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.8498\n","Epoch 1674/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6992e-05 - accuracy: 1.0000\n","Epoch 1674: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.6686e-05 - accuracy: 1.0000 - val_loss: 1.5939 - val_accuracy: 0.7629\n","Epoch 1675/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.1322e-04 - accuracy: 0.9997\n","Epoch 1675: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.0582e-04 - accuracy: 0.9997 - val_loss: 6.4136 - val_accuracy: 0.4816\n","Epoch 1676/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1438e-04 - accuracy: 1.0000\n","Epoch 1676: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1438e-04 - accuracy: 1.0000 - val_loss: 1.0085 - val_accuracy: 0.7938\n","Epoch 1677/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.1066e-05 - accuracy: 1.0000\n","Epoch 1677: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1109e-05 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8395\n","Epoch 1678/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7193e-05 - accuracy: 1.0000\n","Epoch 1678: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6976e-05 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.8247\n","Epoch 1679/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8355e-05 - accuracy: 1.0000\n","Epoch 1679: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8112e-05 - accuracy: 1.0000 - val_loss: 0.7828 - val_accuracy: 0.8277\n","Epoch 1680/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2752e-05 - accuracy: 1.0000\n","Epoch 1680: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2752e-05 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8306\n","Epoch 1681/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.4451e-05 - accuracy: 1.0000\n","Epoch 1681: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.4451e-05 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.8071\n","Epoch 1682/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4066e-05 - accuracy: 1.0000\n","Epoch 1682: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4066e-05 - accuracy: 1.0000 - val_loss: 0.7673 - val_accuracy: 0.8277\n","Epoch 1683/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.6940e-06 - accuracy: 1.0000\n","Epoch 1683: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.6675e-06 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.8321\n","Epoch 1684/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.7918e-06 - accuracy: 1.0000\n","Epoch 1684: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.7060e-06 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.8159\n","Epoch 1685/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.2255e-05 - accuracy: 1.0000\n","Epoch 1685: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.2255e-05 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8174\n","Epoch 1686/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.8700e-05 - accuracy: 1.0000\n","Epoch 1686: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8700e-05 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.8218\n","Epoch 1687/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.6964e-06 - accuracy: 1.0000\n","Epoch 1687: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6651e-06 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.8174\n","Epoch 1688/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4651e-05 - accuracy: 1.0000\n","Epoch 1688: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4651e-05 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8174\n","Epoch 1689/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.1393e-06 - accuracy: 1.0000\n","Epoch 1689: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.1393e-06 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.8130\n","Epoch 1690/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0328e-06 - accuracy: 1.0000\n","Epoch 1690: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0328e-06 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8233\n","Epoch 1691/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7005e-06 - accuracy: 1.0000\n","Epoch 1691: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0591e-06 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8233\n","Epoch 1692/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.2896e-06 - accuracy: 1.0000\n","Epoch 1692: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.2257e-06 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.8306\n","Epoch 1693/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4921e-06 - accuracy: 1.0000\n","Epoch 1693: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.4719e-06 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.8336\n","Epoch 1694/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9997\n","Epoch 1694: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 1.3207 - val_accuracy: 0.7054\n","Epoch 1695/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5275e-04 - accuracy: 1.0000\n","Epoch 1695: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5275e-04 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.7644\n","Epoch 1696/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4827e-05 - accuracy: 1.0000\n","Epoch 1696: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4628e-05 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.8174\n","Epoch 1697/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.5250e-05 - accuracy: 1.0000\n","Epoch 1697: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.4394e-05 - accuracy: 1.0000 - val_loss: 0.7372 - val_accuracy: 0.8144\n","Epoch 1698/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6923e-05 - accuracy: 1.0000\n","Epoch 1698: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6776e-05 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8233\n","Epoch 1699/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.0930e-04 - accuracy: 1.0000\n","Epoch 1699: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.0460e-04 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8056\n","Epoch 1700/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.9672e-05 - accuracy: 1.0000\n","Epoch 1700: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.9149e-05 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.7953\n","Epoch 1701/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6329e-05 - accuracy: 1.0000\n","Epoch 1701: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.5914e-05 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.7923\n","Epoch 1702/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.6472e-05 - accuracy: 1.0000\n","Epoch 1702: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6575e-05 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.8115\n","Epoch 1703/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9833e-06 - accuracy: 1.0000\n","Epoch 1703: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0151e-06 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8071\n","Epoch 1704/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1157e-05 - accuracy: 1.0000\n","Epoch 1704: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1157e-05 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.8189\n","Epoch 1705/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2964e-06 - accuracy: 1.0000\n","Epoch 1705: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.2964e-06 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8174\n","Epoch 1706/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4820e-05 - accuracy: 1.0000\n","Epoch 1706: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4766e-05 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8189\n","Epoch 1707/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.6396e-05 - accuracy: 1.0000\n","Epoch 1707: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6396e-05 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8159\n","Epoch 1708/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4921e-05 - accuracy: 1.0000\n","Epoch 1708: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4820e-05 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.8262\n","Epoch 1709/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3963e-05 - accuracy: 1.0000\n","Epoch 1709: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3861e-05 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.8189\n","Epoch 1710/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.0315e-06 - accuracy: 1.0000\n","Epoch 1710: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0315e-06 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8130\n","Epoch 1711/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.9537e-05 - accuracy: 1.0000\n","Epoch 1711: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.9537e-05 - accuracy: 1.0000 - val_loss: 1.1523 - val_accuracy: 0.7231\n","Epoch 1712/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9236e-04 - accuracy: 1.0000\n","Epoch 1712: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9061e-04 - accuracy: 1.0000 - val_loss: 1.1834 - val_accuracy: 0.7599\n","Epoch 1713/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.5476e-06 - accuracy: 1.0000\n","Epoch 1713: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.4821e-06 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.8144\n","Epoch 1714/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.5020e-06 - accuracy: 1.0000\n","Epoch 1714: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.4715e-06 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8218\n","Epoch 1715/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0958e-05 - accuracy: 1.0000\n","Epoch 1715: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0958e-05 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8321\n","Epoch 1716/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.8632e-06 - accuracy: 1.0000\n","Epoch 1716: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.8632e-06 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8306\n","Epoch 1717/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.8483e-06 - accuracy: 1.0000\n","Epoch 1717: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 6.8483e-06 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8336\n","Epoch 1718/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.4372e-06 - accuracy: 1.0000\n","Epoch 1718: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.4372e-06 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8262\n","Epoch 1719/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.4891e-06 - accuracy: 1.0000\n","Epoch 1719: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 9.4094e-06 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8336\n","Epoch 1720/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.2548e-06 - accuracy: 1.0000\n","Epoch 1720: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2548e-06 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.8380\n","Epoch 1721/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1113e-05 - accuracy: 1.0000\n","Epoch 1721: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0749e-05 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.7717\n","Epoch 1722/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4976e-04 - accuracy: 0.9997\n","Epoch 1722: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4976e-04 - accuracy: 0.9997 - val_loss: 2.5414 - val_accuracy: 0.6156\n","Epoch 1723/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2632e-04 - accuracy: 1.0000\n","Epoch 1723: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2632e-04 - accuracy: 1.0000 - val_loss: 0.8803 - val_accuracy: 0.7673\n","Epoch 1724/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.9761e-06 - accuracy: 1.0000\n","Epoch 1724: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 8.9761e-06 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8144\n","Epoch 1725/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5144e-05 - accuracy: 1.0000\n","Epoch 1725: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5059e-05 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8262\n","Epoch 1726/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8966e-05 - accuracy: 1.0000\n","Epoch 1726: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8722e-05 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8189\n","Epoch 1727/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2061e-05 - accuracy: 1.0000\n","Epoch 1727: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2061e-05 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.8277\n","Epoch 1728/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9270e-04 - accuracy: 1.0000\n","Epoch 1728: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9092e-04 - accuracy: 1.0000 - val_loss: 0.6299 - val_accuracy: 0.8115\n","Epoch 1729/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7839e-05 - accuracy: 1.0000\n","Epoch 1729: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.7839e-05 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8085\n","Epoch 1730/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2653e-05 - accuracy: 1.0000\n","Epoch 1730: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2653e-05 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8012\n","Epoch 1731/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.0820e-06 - accuracy: 1.0000\n","Epoch 1731: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.0820e-06 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.8144\n","Epoch 1732/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.8147e-06 - accuracy: 1.0000\n","Epoch 1732: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8147e-06 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.8189\n","Epoch 1733/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.5851e-06 - accuracy: 1.0000\n","Epoch 1733: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.5851e-06 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.8233\n","Epoch 1734/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4474e-06 - accuracy: 1.0000\n","Epoch 1734: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4292e-06 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.8233\n","Epoch 1735/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.5079e-06 - accuracy: 1.0000\n","Epoch 1735: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.4649e-06 - accuracy: 1.0000 - val_loss: 0.5859 - val_accuracy: 0.8262\n","Epoch 1736/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6654e-06 - accuracy: 1.0000\n","Epoch 1736: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.6389e-06 - accuracy: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.8306\n","Epoch 1737/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6060e-05 - accuracy: 1.0000\n","Epoch 1737: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.5646e-05 - accuracy: 1.0000 - val_loss: 0.8010 - val_accuracy: 0.7997\n","Epoch 1738/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7951e-05 - accuracy: 1.0000\n","Epoch 1738: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7951e-05 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.7968\n","Epoch 1739/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6000e-06 - accuracy: 1.0000\n","Epoch 1739: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.5435e-06 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.8218\n","Epoch 1740/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2491e-05 - accuracy: 1.0000\n","Epoch 1740: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2491e-05 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8498\n","Epoch 1741/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.1076e-06 - accuracy: 1.0000\n","Epoch 1741: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.0361e-06 - accuracy: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.8498\n","Epoch 1742/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1861e-04 - accuracy: 1.0000\n","Epoch 1742: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1672e-04 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.7143\n","Epoch 1743/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2657e-05 - accuracy: 1.0000\n","Epoch 1743: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2463e-05 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.8041\n","Epoch 1744/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2080e-06 - accuracy: 1.0000\n","Epoch 1744: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.2112e-06 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.8174\n","Epoch 1745/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0168e-05 - accuracy: 1.0000\n","Epoch 1745: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 1.0168e-05 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.8144\n","Epoch 1746/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0854e-05 - accuracy: 1.0000\n","Epoch 1746: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.0595e-05 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.7997\n","Epoch 1747/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.0345e-06 - accuracy: 1.0000\n","Epoch 1747: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.0345e-06 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.8203\n","Epoch 1748/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.8662e-06 - accuracy: 1.0000\n","Epoch 1748: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.8327e-06 - accuracy: 1.0000 - val_loss: 0.6566 - val_accuracy: 0.8247\n","Epoch 1749/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.1343e-06 - accuracy: 1.0000\n","Epoch 1749: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1343e-06 - accuracy: 1.0000 - val_loss: 0.6577 - val_accuracy: 0.8277\n","Epoch 1750/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4192e-05 - accuracy: 1.0000\n","Epoch 1750: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4064e-05 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.8306\n","Epoch 1751/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.2337e-06 - accuracy: 1.0000\n","Epoch 1751: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.1773e-06 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8203\n","Epoch 1752/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2806e-06 - accuracy: 1.0000\n","Epoch 1752: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2841e-06 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 0.8262\n","Epoch 1753/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.7092e-06 - accuracy: 1.0000\n","Epoch 1753: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.6787e-06 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.8277\n","Epoch 1754/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6205e-06 - accuracy: 1.0000\n","Epoch 1754: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.5611e-06 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.8306\n","Epoch 1755/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8220e-06 - accuracy: 1.0000\n","Epoch 1755: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8669e-06 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.8292\n","Epoch 1756/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.5870e-06 - accuracy: 1.0000\n","Epoch 1756: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.5367e-06 - accuracy: 1.0000 - val_loss: 0.6006 - val_accuracy: 0.8424\n","Epoch 1757/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.0126e-06 - accuracy: 1.0000\n","Epoch 1757: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0126e-06 - accuracy: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.8395\n","Epoch 1758/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2321e-06 - accuracy: 1.0000\n","Epoch 1758: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2321e-06 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.8321\n","Epoch 1759/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.3026e-06 - accuracy: 1.0000\n","Epoch 1759: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.2316e-06 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.8218\n","Epoch 1760/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4299e-06 - accuracy: 1.0000\n","Epoch 1760: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 1.4201e-06 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.8292\n","Epoch 1761/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9503e-06 - accuracy: 1.0000\n","Epoch 1761: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9503e-06 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8306\n","Epoch 1762/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.0122e-06 - accuracy: 1.0000\n","Epoch 1762: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0122e-06 - accuracy: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.8292\n","Epoch 1763/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7238e-06 - accuracy: 1.0000\n","Epoch 1763: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7032e-06 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.8365\n","Epoch 1764/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5054e-06 - accuracy: 1.0000\n","Epoch 1764: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4854e-06 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8454\n","Epoch 1765/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9993e-06 - accuracy: 1.0000\n","Epoch 1765: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9987e-06 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.8409\n","Epoch 1766/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3897e-06 - accuracy: 1.0000\n","Epoch 1766: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3897e-06 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.8336\n","Epoch 1767/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.6116e-06 - accuracy: 1.0000\n","Epoch 1767: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.5793e-06 - accuracy: 1.0000 - val_loss: 0.5735 - val_accuracy: 0.8365\n","Epoch 1768/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1668e-06 - accuracy: 1.0000\n","Epoch 1768: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1668e-06 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.8247\n","Epoch 1769/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3768e-06 - accuracy: 1.0000\n","Epoch 1769: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3768e-06 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.8380\n","Epoch 1770/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4038e-06 - accuracy: 1.0000\n","Epoch 1770: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4038e-06 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.8351\n","Epoch 1771/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5874e-06 - accuracy: 1.0000\n","Epoch 1771: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5739e-06 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.8365\n","Epoch 1772/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8510e-06 - accuracy: 1.0000\n","Epoch 1772: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8460e-06 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.8292\n","Epoch 1773/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2391e-06 - accuracy: 1.0000\n","Epoch 1773: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 6s 49ms/step - loss: 1.2286e-06 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.8292\n","Epoch 1774/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1963e-06 - accuracy: 1.0000\n","Epoch 1774: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1963e-06 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.8306\n","Epoch 1775/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2585e-06 - accuracy: 1.0000\n","Epoch 1775: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2585e-06 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.8321\n","Epoch 1776/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8770e-06 - accuracy: 1.0000\n","Epoch 1776: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.8546e-06 - accuracy: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.8262\n","Epoch 1777/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0352e-06 - accuracy: 1.0000\n","Epoch 1777: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0267e-06 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8321\n","Epoch 1778/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3489e-06 - accuracy: 1.0000\n","Epoch 1778: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3487e-06 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 0.8365\n","Epoch 1779/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.7859e-07 - accuracy: 1.0000\n","Epoch 1779: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.7859e-07 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.8306\n","Epoch 1780/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.8215e-07 - accuracy: 1.0000\n","Epoch 1780: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.8681e-07 - accuracy: 1.0000 - val_loss: 0.5690 - val_accuracy: 0.8336\n","Epoch 1781/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3780e-06 - accuracy: 1.0000\n","Epoch 1781: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3580e-06 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 0.8380\n","Epoch 1782/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.0204e-07 - accuracy: 1.0000\n","Epoch 1782: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.0204e-07 - accuracy: 1.0000 - val_loss: 0.5636 - val_accuracy: 0.8351\n","Epoch 1783/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.6745e-07 - accuracy: 1.0000\n","Epoch 1783: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.9951e-07 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.8351\n","Epoch 1784/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4175e-06 - accuracy: 1.0000\n","Epoch 1784: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.3867e-06 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8395\n","Epoch 1785/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.7272e-07 - accuracy: 1.0000\n","Epoch 1785: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.7272e-07 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.8380\n","Epoch 1786/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.8707e-07 - accuracy: 1.0000\n","Epoch 1786: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.8316e-07 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8351\n","Epoch 1787/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3883e-06 - accuracy: 1.0000\n","Epoch 1787: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3883e-06 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 0.8262\n","Epoch 1788/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1180e-06 - accuracy: 1.0000\n","Epoch 1788: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1180e-06 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.8424\n","Epoch 1789/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3737e-06 - accuracy: 1.0000\n","Epoch 1789: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3737e-06 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.8409\n","Epoch 1790/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.4244e-07 - accuracy: 1.0000\n","Epoch 1790: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.3798e-07 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.8306\n","Epoch 1791/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9024e-07 - accuracy: 1.0000\n","Epoch 1791: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8916e-07 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.8380\n","Epoch 1792/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6888e-06 - accuracy: 1.0000\n","Epoch 1792: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6888e-06 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8365\n","Epoch 1793/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2301e-06 - accuracy: 1.0000\n","Epoch 1793: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2301e-06 - accuracy: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.8321\n","Epoch 1794/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2864e-06 - accuracy: 1.0000\n","Epoch 1794: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2671e-06 - accuracy: 1.0000 - val_loss: 0.5268 - val_accuracy: 0.8380\n","Epoch 1795/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.8042e-07 - accuracy: 1.0000\n","Epoch 1795: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.7432e-07 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.8233\n","Epoch 1796/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9247e-06 - accuracy: 1.0000\n","Epoch 1796: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9002e-06 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.8203\n","Epoch 1797/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3291e-05 - accuracy: 1.0000\n","Epoch 1797: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3195e-05 - accuracy: 1.0000 - val_loss: 1.7363 - val_accuracy: 0.6760\n","Epoch 1798/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4703e-06 - accuracy: 1.0000\n","Epoch 1798: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4385e-06 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.8380\n","Epoch 1799/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2499e-05 - accuracy: 1.0000\n","Epoch 1799: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2499e-05 - accuracy: 1.0000 - val_loss: 1.9974 - val_accuracy: 0.6392\n","Epoch 1800/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.6328e-06 - accuracy: 1.0000\n","Epoch 1800: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.5735e-06 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.8027\n","Epoch 1801/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7276e-06 - accuracy: 1.0000\n","Epoch 1801: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7276e-06 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.8409\n","Epoch 1802/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7644e-06 - accuracy: 1.0000\n","Epoch 1802: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 1.7497e-06 - accuracy: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.8498\n","Epoch 1803/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7616e-06 - accuracy: 1.0000\n","Epoch 1803: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7616e-06 - accuracy: 1.0000 - val_loss: 0.5491 - val_accuracy: 0.8454\n","Epoch 1804/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2408e-06 - accuracy: 1.0000\n","Epoch 1804: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2374e-06 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8557\n","Epoch 1805/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9780e-06 - accuracy: 1.0000\n","Epoch 1805: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9636e-06 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8513\n","Epoch 1806/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3123e-06 - accuracy: 1.0000\n","Epoch 1806: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3123e-06 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8498\n","Epoch 1807/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1738e-06 - accuracy: 1.0000\n","Epoch 1807: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1685e-06 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8468\n","Epoch 1808/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4134e-07 - accuracy: 1.0000\n","Epoch 1808: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.3905e-07 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8571\n","Epoch 1809/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.1142e-06 - accuracy: 1.0000\n","Epoch 1809: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0796e-06 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.8424\n","Epoch 1810/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7627e-05 - accuracy: 1.0000\n","Epoch 1810: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7627e-05 - accuracy: 1.0000 - val_loss: 4.6077 - val_accuracy: 0.5552\n","Epoch 1811/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.0247e-04 - accuracy: 1.0000\n","Epoch 1811: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0247e-04 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.7025\n","Epoch 1812/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9985\n","Epoch 1812: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 2.7196 - val_accuracy: 0.5803\n","Epoch 1813/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9980\n","Epoch 1813: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 2.1863 - val_accuracy: 0.6112\n","Epoch 1814/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9986\n","Epoch 1814: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.9571 - val_accuracy: 0.7894\n","Epoch 1815/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1157e-04 - accuracy: 1.0000\n","Epoch 1815: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1188e-04 - accuracy: 1.0000 - val_loss: 0.8356 - val_accuracy: 0.7835\n","Epoch 1816/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.4838e-05 - accuracy: 1.0000\n","Epoch 1816: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.4836e-05 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7953\n","Epoch 1817/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2326e-04 - accuracy: 1.0000\n","Epoch 1817: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2304e-04 - accuracy: 1.0000 - val_loss: 0.7446 - val_accuracy: 0.8071\n","Epoch 1818/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3296e-05 - accuracy: 1.0000\n","Epoch 1818: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3296e-05 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8130\n","Epoch 1819/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0484e-05 - accuracy: 1.0000\n","Epoch 1819: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0454e-05 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.8174\n","Epoch 1820/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.3348e-05 - accuracy: 1.0000\n","Epoch 1820: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.3348e-05 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8233\n","Epoch 1821/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8734e-05 - accuracy: 1.0000\n","Epoch 1821: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8676e-05 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.8233\n","Epoch 1822/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.7758e-05 - accuracy: 1.0000\n","Epoch 1822: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7646e-05 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8262\n","Epoch 1823/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.8095e-06 - accuracy: 1.0000\n","Epoch 1823: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.8095e-06 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8247\n","Epoch 1824/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2222e-05 - accuracy: 1.0000\n","Epoch 1824: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2222e-05 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8233\n","Epoch 1825/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9555e-05 - accuracy: 1.0000\n","Epoch 1825: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9112e-05 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8233\n","Epoch 1826/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.3581e-05 - accuracy: 1.0000\n","Epoch 1826: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3131e-05 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.8380\n","Epoch 1827/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1567e-05 - accuracy: 1.0000\n","Epoch 1827: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1483e-05 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8395\n","Epoch 1828/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2170e-05 - accuracy: 1.0000\n","Epoch 1828: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2153e-05 - accuracy: 1.0000 - val_loss: 0.6246 - val_accuracy: 0.8424\n","Epoch 1829/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1993e-05 - accuracy: 1.0000\n","Epoch 1829: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1872e-05 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.8439\n","Epoch 1830/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.7871e-06 - accuracy: 1.0000\n","Epoch 1830: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.7871e-06 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.8454\n","Epoch 1831/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0498e-05 - accuracy: 1.0000\n","Epoch 1831: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 6s 49ms/step - loss: 1.0482e-05 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.8454\n","Epoch 1832/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5768e-05 - accuracy: 1.0000\n","Epoch 1832: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5663e-05 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.8468\n","Epoch 1833/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.3806e-06 - accuracy: 1.0000\n","Epoch 1833: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3806e-06 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.8498\n","Epoch 1834/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.5558e-06 - accuracy: 1.0000\n","Epoch 1834: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2172e-05 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.8483\n","Epoch 1835/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6793e-05 - accuracy: 1.0000\n","Epoch 1835: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6654e-05 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.8483\n","Epoch 1836/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.1272e-06 - accuracy: 1.0000\n","Epoch 1836: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1272e-06 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8454\n","Epoch 1837/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0532e-05 - accuracy: 1.0000\n","Epoch 1837: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0532e-05 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.8527\n","Epoch 1838/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5419e-06 - accuracy: 1.0000\n","Epoch 1838: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4863e-06 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.8498\n","Epoch 1839/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.0216e-06 - accuracy: 1.0000\n","Epoch 1839: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.9697e-06 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.8498\n","Epoch 1840/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5653e-06 - accuracy: 1.0000\n","Epoch 1840: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.5386e-06 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.8513\n","Epoch 1841/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.8305e-06 - accuracy: 1.0000\n","Epoch 1841: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8305e-06 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8542\n","Epoch 1842/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.4715e-06 - accuracy: 1.0000\n","Epoch 1842: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.4058e-06 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.8527\n","Epoch 1843/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.3305e-06 - accuracy: 1.0000\n","Epoch 1843: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.4781e-06 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.8557\n","Epoch 1844/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4115e-06 - accuracy: 1.0000\n","Epoch 1844: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4115e-06 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8557\n","Epoch 1845/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9088e-06 - accuracy: 1.0000\n","Epoch 1845: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9228e-06 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8542\n","Epoch 1846/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4943e-06 - accuracy: 1.0000\n","Epoch 1846: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.4477e-06 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.8571\n","Epoch 1847/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.5639e-06 - accuracy: 1.0000\n","Epoch 1847: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.5639e-06 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.8542\n","Epoch 1848/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.4102e-06 - accuracy: 1.0000\n","Epoch 1848: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3845e-06 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.8571\n","Epoch 1849/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5930e-06 - accuracy: 1.0000\n","Epoch 1849: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.5402e-06 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.8586\n","Epoch 1850/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.8567e-06 - accuracy: 1.0000\n","Epoch 1850: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.8567e-06 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8557\n","Epoch 1851/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2150e-06 - accuracy: 1.0000\n","Epoch 1851: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.2150e-06 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.8601\n","Epoch 1852/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.6503e-06 - accuracy: 1.0000\n","Epoch 1852: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.6048e-06 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.8616\n","Epoch 1853/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1026e-06 - accuracy: 1.0000\n","Epoch 1853: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1026e-06 - accuracy: 1.0000 - val_loss: 0.5657 - val_accuracy: 0.8616\n","Epoch 1854/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3695e-06 - accuracy: 1.0000\n","Epoch 1854: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3333e-06 - accuracy: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.8586\n","Epoch 1855/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.2368e-06 - accuracy: 1.0000\n","Epoch 1855: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.2368e-06 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.8601\n","Epoch 1856/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7071e-06 - accuracy: 1.0000\n","Epoch 1856: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.7071e-06 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.8601\n","Epoch 1857/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.3287e-04 - accuracy: 0.9997\n","Epoch 1857: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.2428e-04 - accuracy: 0.9997 - val_loss: 1.8695 - val_accuracy: 0.5626\n","Epoch 1858/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.3887e-04 - accuracy: 0.9997\n","Epoch 1858: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.3331e-04 - accuracy: 0.9997 - val_loss: 1.0656 - val_accuracy: 0.7437\n","Epoch 1859/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.9249e-05 - accuracy: 1.0000\n","Epoch 1859: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.9249e-05 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.7791\n","Epoch 1860/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.1053e-05 - accuracy: 1.0000\n","Epoch 1860: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.0270e-05 - accuracy: 1.0000 - val_loss: 0.9135 - val_accuracy: 0.7953\n","Epoch 1861/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.2110e-05 - accuracy: 1.0000\n","Epoch 1861: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2110e-05 - accuracy: 1.0000 - val_loss: 1.0220 - val_accuracy: 0.7850\n","Epoch 1862/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.7808e-06 - accuracy: 1.0000\n","Epoch 1862: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.7470e-06 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.7968\n","Epoch 1863/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1612e-05 - accuracy: 1.0000\n","Epoch 1863: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1469e-05 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.7923\n","Epoch 1864/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6340e-05 - accuracy: 1.0000\n","Epoch 1864: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6129e-05 - accuracy: 1.0000 - val_loss: 0.8896 - val_accuracy: 0.8115\n","Epoch 1865/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.3636e-05 - accuracy: 1.0000\n","Epoch 1865: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 5.3636e-05 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.8115\n","Epoch 1866/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5164e-05 - accuracy: 1.0000\n","Epoch 1866: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5164e-05 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.7997\n","Epoch 1867/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.6962e-06 - accuracy: 1.0000\n","Epoch 1867: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.6747e-06 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.8056\n","Epoch 1868/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.0955e-05 - accuracy: 1.0000\n","Epoch 1868: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0955e-05 - accuracy: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.8174\n","Epoch 1869/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.1362e-06 - accuracy: 1.0000\n","Epoch 1869: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.1362e-06 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.8130\n","Epoch 1870/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5847e-05 - accuracy: 1.0000\n","Epoch 1870: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5847e-05 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.8041\n","Epoch 1871/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.2067e-06 - accuracy: 1.0000\n","Epoch 1871: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.1723e-06 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.8085\n","Epoch 1872/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9679e-05 - accuracy: 1.0000\n","Epoch 1872: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9679e-05 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.7997\n","Epoch 1873/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.3129e-06 - accuracy: 1.0000\n","Epoch 1873: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.2649e-06 - accuracy: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.8159\n","Epoch 1874/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4305e-05 - accuracy: 1.0000\n","Epoch 1874: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4271e-05 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.8012\n","Epoch 1875/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.8946e-05 - accuracy: 1.0000\n","Epoch 1875: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.8946e-05 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8527\n","Epoch 1876/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.4988e-06 - accuracy: 1.0000\n","Epoch 1876: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.4808e-06 - accuracy: 1.0000 - val_loss: 0.7380 - val_accuracy: 0.8424\n","Epoch 1877/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2928e-06 - accuracy: 1.0000\n","Epoch 1877: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.2646e-06 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8380\n","Epoch 1878/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5419e-06 - accuracy: 1.0000\n","Epoch 1878: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5419e-06 - accuracy: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.8395\n","Epoch 1879/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.2547e-06 - accuracy: 1.0000\n","Epoch 1879: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.2547e-06 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.8189\n","Epoch 1880/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.3184e-06 - accuracy: 1.0000\n","Epoch 1880: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.2473e-06 - accuracy: 1.0000 - val_loss: 0.7916 - val_accuracy: 0.8351\n","Epoch 1881/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.2613e-06 - accuracy: 1.0000\n","Epoch 1881: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 6s 49ms/step - loss: 4.2613e-06 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.8395\n","Epoch 1882/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3093e-05 - accuracy: 1.0000\n","Epoch 1882: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3093e-05 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 0.8027\n","Epoch 1883/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.6501e-06 - accuracy: 1.0000\n","Epoch 1883: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6501e-06 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8218\n","Epoch 1884/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1295e-06 - accuracy: 1.0000\n","Epoch 1884: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1132e-06 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8277\n","Epoch 1885/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1246e-06 - accuracy: 1.0000\n","Epoch 1885: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1058e-06 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.8321\n","Epoch 1886/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.3802e-06 - accuracy: 1.0000\n","Epoch 1886: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.3802e-06 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.8306\n","Epoch 1887/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7684e-06 - accuracy: 1.0000\n","Epoch 1887: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7684e-06 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8306\n","Epoch 1888/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.5513e-05 - accuracy: 1.0000\n","Epoch 1888: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5513e-05 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.8527\n","Epoch 1889/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.3584e-06 - accuracy: 1.0000\n","Epoch 1889: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.3068e-06 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8527\n","Epoch 1890/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.7504e-05 - accuracy: 1.0000\n","Epoch 1890: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.6881e-05 - accuracy: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.8130\n","Epoch 1891/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0104e-06 - accuracy: 1.0000\n","Epoch 1891: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9902e-06 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.8277\n","Epoch 1892/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9743e-06 - accuracy: 1.0000\n","Epoch 1892: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9711e-06 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.8306\n","Epoch 1893/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.9779e-06 - accuracy: 1.0000\n","Epoch 1893: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.9231e-06 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.8292\n","Epoch 1894/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.2828e-06 - accuracy: 1.0000\n","Epoch 1894: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2466e-06 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.8277\n","Epoch 1895/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1942e-06 - accuracy: 1.0000\n","Epoch 1895: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1892e-06 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.8336\n","Epoch 1896/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7221e-06 - accuracy: 1.0000\n","Epoch 1896: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6987e-06 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.8365\n","Epoch 1897/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.5532e-06 - accuracy: 1.0000\n","Epoch 1897: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.5208e-06 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.8321\n","Epoch 1898/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5768e-06 - accuracy: 1.0000\n","Epoch 1898: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.5204e-06 - accuracy: 1.0000 - val_loss: 0.7692 - val_accuracy: 0.8380\n","Epoch 1899/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7138e-06 - accuracy: 1.0000\n","Epoch 1899: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6920e-06 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.8409\n","Epoch 1900/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7600e-06 - accuracy: 1.0000\n","Epoch 1900: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7600e-06 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 0.8424\n","Epoch 1901/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2708e-06 - accuracy: 1.0000\n","Epoch 1901: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2708e-06 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.8351\n","Epoch 1902/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9587e-06 - accuracy: 1.0000\n","Epoch 1902: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9456e-06 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8351\n","Epoch 1903/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6665e-06 - accuracy: 1.0000\n","Epoch 1903: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6427e-06 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8336\n","Epoch 1904/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.4862e-07 - accuracy: 1.0000\n","Epoch 1904: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.5870e-07 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8351\n","Epoch 1905/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4579e-06 - accuracy: 1.0000\n","Epoch 1905: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4396e-06 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8321\n","Epoch 1906/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3355e-06 - accuracy: 1.0000\n","Epoch 1906: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3355e-06 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8321\n","Epoch 1907/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1306e-05 - accuracy: 1.0000\n","Epoch 1907: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1221e-05 - accuracy: 1.0000 - val_loss: 1.4335 - val_accuracy: 0.7688\n","Epoch 1908/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5072e-06 - accuracy: 1.0000\n","Epoch 1908: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.4821e-06 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.7923\n","Epoch 1909/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.8307e-06 - accuracy: 1.0000\n","Epoch 1909: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.8179e-06 - accuracy: 1.0000 - val_loss: 0.7730 - val_accuracy: 0.8233\n","Epoch 1910/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0858e-06 - accuracy: 1.0000\n","Epoch 1910: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0858e-06 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.8144\n","Epoch 1911/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.9594e-06 - accuracy: 1.0000\n","Epoch 1911: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9594e-06 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.8144\n","Epoch 1912/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1537e-06 - accuracy: 1.0000\n","Epoch 1912: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1351e-06 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.8100\n","Epoch 1913/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1192e-04 - accuracy: 1.0000\n","Epoch 1913: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1090e-04 - accuracy: 1.0000 - val_loss: 11.2521 - val_accuracy: 0.2371\n","Epoch 1914/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 1914: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.4719 - val_accuracy: 0.4345\n","Epoch 1915/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.0424e-04 - accuracy: 0.9997\n","Epoch 1915: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.9784e-04 - accuracy: 0.9997 - val_loss: 3.0145 - val_accuracy: 0.5979\n","Epoch 1916/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7694e-04 - accuracy: 1.0000\n","Epoch 1916: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7694e-04 - accuracy: 1.0000 - val_loss: 0.9755 - val_accuracy: 0.7982\n","Epoch 1917/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 1917: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 1.9880 - val_accuracy: 0.7040\n","Epoch 1918/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n","Epoch 1918: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.7313 - val_accuracy: 0.7820\n","Epoch 1919/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.9927e-05 - accuracy: 1.0000\n","Epoch 1919: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.9203e-05 - accuracy: 1.0000 - val_loss: 0.6297 - val_accuracy: 0.8056\n","Epoch 1920/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9449e-04 - accuracy: 1.0000\n","Epoch 1920: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9274e-04 - accuracy: 1.0000 - val_loss: 0.6092 - val_accuracy: 0.8056\n","Epoch 1921/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n","Epoch 1921: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.5738 - val_accuracy: 0.6907\n","Epoch 1922/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.3217e-05 - accuracy: 1.0000\n","Epoch 1922: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2641e-05 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.7997\n","Epoch 1923/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9608e-05 - accuracy: 1.0000\n","Epoch 1923: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.9942e-05 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8041\n","Epoch 1924/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.0940e-05 - accuracy: 1.0000\n","Epoch 1924: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.0940e-05 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.8085\n","Epoch 1925/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.5020e-05 - accuracy: 1.0000\n","Epoch 1925: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.4540e-05 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.8115\n","Epoch 1926/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.6565e-05 - accuracy: 1.0000\n","Epoch 1926: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.6565e-05 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.8144\n","Epoch 1927/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4966e-05 - accuracy: 1.0000\n","Epoch 1927: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4674e-05 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.8071\n","Epoch 1928/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8324e-05 - accuracy: 1.0000\n","Epoch 1928: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8320e-05 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.8100\n","Epoch 1929/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.8085e-05 - accuracy: 1.0000\n","Epoch 1929: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8085e-05 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.8174\n","Epoch 1930/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0463e-05 - accuracy: 1.0000\n","Epoch 1930: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0257e-05 - accuracy: 1.0000 - val_loss: 0.5822 - val_accuracy: 0.8218\n","Epoch 1931/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.7466e-05 - accuracy: 1.0000\n","Epoch 1931: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.6569e-05 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.8159\n","Epoch 1932/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.2383e-04 - accuracy: 0.9997\n","Epoch 1932: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1997e-04 - accuracy: 0.9997 - val_loss: 0.5612 - val_accuracy: 0.8395\n","Epoch 1933/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0063e-04 - accuracy: 1.0000\n","Epoch 1933: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0063e-04 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.8306\n","Epoch 1934/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0865e-05 - accuracy: 1.0000\n","Epoch 1934: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0674e-05 - accuracy: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.8218\n","Epoch 1935/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2471e-05 - accuracy: 1.0000\n","Epoch 1935: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2590e-05 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.8100\n","Epoch 1936/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9285e-05 - accuracy: 1.0000\n","Epoch 1936: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9052e-05 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.8130\n","Epoch 1937/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1252e-05 - accuracy: 1.0000\n","Epoch 1937: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1176e-05 - accuracy: 1.0000 - val_loss: 0.6494 - val_accuracy: 0.8130\n","Epoch 1938/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5679e-05 - accuracy: 1.0000\n","Epoch 1938: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5679e-05 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.8085\n","Epoch 1939/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.1805e-06 - accuracy: 1.0000\n","Epoch 1939: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.1497e-06 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8056\n","Epoch 1940/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7722e-05 - accuracy: 1.0000\n","Epoch 1940: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7722e-05 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.8056\n","Epoch 1941/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5960e-05 - accuracy: 1.0000\n","Epoch 1941: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5843e-05 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.8085\n","Epoch 1942/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6249e-05 - accuracy: 1.0000\n","Epoch 1942: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6104e-05 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.8115\n","Epoch 1943/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7655e-04 - accuracy: 1.0000\n","Epoch 1943: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7491e-04 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.7791\n","Epoch 1944/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.0746e-06 - accuracy: 1.0000\n","Epoch 1944: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 6s 49ms/step - loss: 9.0243e-06 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.8189\n","Epoch 1945/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0148e-04 - accuracy: 1.0000\n","Epoch 1945: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0066e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8233\n","Epoch 1946/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1230e-05 - accuracy: 1.0000\n","Epoch 1946: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1230e-05 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.8380\n","Epoch 1947/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.4672e-04 - accuracy: 1.0000\n","Epoch 1947: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4672e-04 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.8247\n","Epoch 1948/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0780e-05 - accuracy: 1.0000\n","Epoch 1948: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0780e-05 - accuracy: 1.0000 - val_loss: 0.5399 - val_accuracy: 0.8557\n","Epoch 1949/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.9176e-06 - accuracy: 1.0000\n","Epoch 1949: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.9176e-06 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.8262\n","Epoch 1950/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0876e-05 - accuracy: 1.0000\n","Epoch 1950: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0791e-05 - accuracy: 1.0000 - val_loss: 0.5783 - val_accuracy: 0.8233\n","Epoch 1951/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.7579e-06 - accuracy: 1.0000\n","Epoch 1951: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.7579e-06 - accuracy: 1.0000 - val_loss: 0.5810 - val_accuracy: 0.8247\n","Epoch 1952/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.4631e-06 - accuracy: 1.0000\n","Epoch 1952: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.4711e-06 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.8247\n","Epoch 1953/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4955e-06 - accuracy: 1.0000\n","Epoch 1953: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.4903e-06 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8262\n","Epoch 1954/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3460e-05 - accuracy: 1.0000\n","Epoch 1954: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3364e-05 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.8262\n","Epoch 1955/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6036e-06 - accuracy: 1.0000\n","Epoch 1955: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.5875e-06 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8233\n","Epoch 1956/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.5062e-06 - accuracy: 1.0000\n","Epoch 1956: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.5604e-06 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.8203\n","Epoch 1957/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4221e-05 - accuracy: 1.0000\n","Epoch 1957: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4014e-05 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.8071\n","Epoch 1958/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2815e-04 - accuracy: 1.0000\n","Epoch 1958: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2646e-04 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.7761\n","Epoch 1959/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1118e-04 - accuracy: 1.0000\n","Epoch 1959: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1018e-04 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.7614\n","Epoch 1960/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5689e-05 - accuracy: 1.0000\n","Epoch 1960: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5601e-05 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.8130\n","Epoch 1961/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8682e-06 - accuracy: 1.0000\n","Epoch 1961: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.8682e-06 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8233\n","Epoch 1962/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9070e-05 - accuracy: 1.0000\n","Epoch 1962: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9070e-05 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.8218\n","Epoch 1963/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0417e-05 - accuracy: 1.0000\n","Epoch 1963: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0417e-05 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.8262\n","Epoch 1964/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7846e-05 - accuracy: 1.0000\n","Epoch 1964: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7846e-05 - accuracy: 1.0000 - val_loss: 0.5692 - val_accuracy: 0.8262\n","Epoch 1965/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n","Epoch 1965: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 4.8552 - val_accuracy: 0.4890\n","Epoch 1966/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.1347e-04 - accuracy: 1.0000\n","Epoch 1966: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1062e-04 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.7452\n","Epoch 1967/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0336e-05 - accuracy: 1.0000\n","Epoch 1967: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.0110e-05 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.8130\n","Epoch 1968/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.3871e-05 - accuracy: 1.0000\n","Epoch 1968: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.3299e-05 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.8306\n","Epoch 1969/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0075e-05 - accuracy: 1.0000\n","Epoch 1969: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0075e-05 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.8395\n","Epoch 1970/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.3608e-05 - accuracy: 1.0000\n","Epoch 1970: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.3608e-05 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.8395\n","Epoch 1971/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9929e-05 - accuracy: 1.0000\n","Epoch 1971: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9929e-05 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.8513\n","Epoch 1972/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3540e-05 - accuracy: 1.0000\n","Epoch 1972: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3461e-05 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.8483\n","Epoch 1973/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3505e-05 - accuracy: 1.0000\n","Epoch 1973: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3392e-05 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.8542\n","Epoch 1974/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6226e-05 - accuracy: 1.0000\n","Epoch 1974: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6088e-05 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.8586\n","Epoch 1975/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1454e-05 - accuracy: 1.0000\n","Epoch 1975: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1374e-05 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.8586\n","Epoch 1976/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.8066e-06 - accuracy: 1.0000\n","Epoch 1976: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.8027e-06 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.8571\n","Epoch 1977/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9632e-05 - accuracy: 1.0000\n","Epoch 1977: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9466e-05 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.8601\n","Epoch 1978/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5523e-05 - accuracy: 1.0000\n","Epoch 1978: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5523e-05 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.8704\n","Epoch 1979/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.2619e-06 - accuracy: 1.0000\n","Epoch 1979: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.1787e-06 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.8778\n","Epoch 1980/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.8456e-06 - accuracy: 1.0000\n","Epoch 1980: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.8456e-06 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.8660\n","Epoch 1981/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.9274e-06 - accuracy: 1.0000\n","Epoch 1981: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.9385e-06 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.8675\n","Epoch 1982/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1486e-04 - accuracy: 1.0000\n","Epoch 1982: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1380e-04 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.8144\n","Epoch 1983/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9971\n","Epoch 1983: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 2.1837 - val_accuracy: 0.6053\n","Epoch 1984/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n","Epoch 1984: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 1.6089 - val_accuracy: 0.7305\n","Epoch 1985/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n","Epoch 1985: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.3154 - val_accuracy: 0.7688\n","Epoch 1986/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.1446e-04 - accuracy: 0.9997\n","Epoch 1986: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.0793e-04 - accuracy: 0.9997 - val_loss: 1.1806 - val_accuracy: 0.7791\n","Epoch 1987/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2597e-05 - accuracy: 1.0000\n","Epoch 1987: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.2730e-05 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.7865\n","Epoch 1988/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1084e-05 - accuracy: 1.0000\n","Epoch 1988: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1084e-05 - accuracy: 1.0000 - val_loss: 1.1528 - val_accuracy: 0.7850\n","Epoch 1989/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9222e-05 - accuracy: 1.0000\n","Epoch 1989: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9259e-05 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.7820\n","Epoch 1990/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.7613e-05 - accuracy: 1.0000\n","Epoch 1990: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.7199e-05 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.7791\n","Epoch 1991/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.0618e-05 - accuracy: 1.0000\n","Epoch 1991: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.9983e-05 - accuracy: 1.0000 - val_loss: 1.1408 - val_accuracy: 0.7820\n","Epoch 1992/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0948e-04 - accuracy: 0.9997\n","Epoch 1992: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.0664e-04 - accuracy: 0.9997 - val_loss: 1.2066 - val_accuracy: 0.7732\n","Epoch 1993/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0963e-05 - accuracy: 1.0000\n","Epoch 1993: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0708e-05 - accuracy: 1.0000 - val_loss: 1.1271 - val_accuracy: 0.7717\n","Epoch 1994/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0436e-04 - accuracy: 1.0000\n","Epoch 1994: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0249e-04 - accuracy: 1.0000 - val_loss: 1.4520 - val_accuracy: 0.7482\n","Epoch 1995/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3049e-05 - accuracy: 1.0000\n","Epoch 1995: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2966e-05 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.7599\n","Epoch 1996/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.0578e-05 - accuracy: 1.0000\n","Epoch 1996: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.0578e-05 - accuracy: 1.0000 - val_loss: 1.2206 - val_accuracy: 0.7717\n","Epoch 1997/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0494e-05 - accuracy: 1.0000\n","Epoch 1997: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0236e-05 - accuracy: 1.0000 - val_loss: 1.2346 - val_accuracy: 0.7747\n","Epoch 1998/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.7773e-05 - accuracy: 1.0000\n","Epoch 1998: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.7429e-05 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.7703\n","Epoch 1999/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.4567e-05 - accuracy: 1.0000\n","Epoch 1999: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.4567e-05 - accuracy: 1.0000 - val_loss: 1.1299 - val_accuracy: 0.7703\n","Epoch 2000/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1854e-05 - accuracy: 1.0000\n","Epoch 2000: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1655e-05 - accuracy: 1.0000 - val_loss: 1.1324 - val_accuracy: 0.7747\n","Epoch 2001/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3239e-05 - accuracy: 1.0000\n","Epoch 2001: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.2941e-05 - accuracy: 1.0000 - val_loss: 1.1490 - val_accuracy: 0.7806\n","Epoch 2002/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.5348e-06 - accuracy: 1.0000\n","Epoch 2002: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.5210e-06 - accuracy: 1.0000 - val_loss: 1.1000 - val_accuracy: 0.7820\n","Epoch 2003/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6533e-05 - accuracy: 1.0000\n","Epoch 2003: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6533e-05 - accuracy: 1.0000 - val_loss: 1.0994 - val_accuracy: 0.7791\n","Epoch 2004/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4556e-05 - accuracy: 1.0000\n","Epoch 2004: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4556e-05 - accuracy: 1.0000 - val_loss: 1.1064 - val_accuracy: 0.7820\n","Epoch 2005/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2548e-05 - accuracy: 1.0000\n","Epoch 2005: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2675e-05 - accuracy: 1.0000 - val_loss: 1.0731 - val_accuracy: 0.7835\n","Epoch 2006/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2911e-05 - accuracy: 1.0000\n","Epoch 2006: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2936e-05 - accuracy: 1.0000 - val_loss: 1.0869 - val_accuracy: 0.7850\n","Epoch 2007/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0352e-05 - accuracy: 1.0000\n","Epoch 2007: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0175e-05 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.7879\n","Epoch 2008/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.7897e-06 - accuracy: 1.0000\n","Epoch 2008: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.7897e-06 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.7850\n","Epoch 2009/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3270e-05 - accuracy: 1.0000\n","Epoch 2009: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3270e-05 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.7938\n","Epoch 2010/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.7840e-05 - accuracy: 1.0000\n","Epoch 2010: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7498e-05 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.7894\n","Epoch 2011/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.3358e-05 - accuracy: 1.0000\n","Epoch 2011: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.3358e-05 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.7879\n","Epoch 2012/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7552e-05 - accuracy: 1.0000\n","Epoch 2012: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7317e-05 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.7894\n","Epoch 2013/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0569e-05 - accuracy: 1.0000\n","Epoch 2013: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0475e-05 - accuracy: 1.0000 - val_loss: 1.0412 - val_accuracy: 0.7938\n","Epoch 2014/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5545e-05 - accuracy: 1.0000\n","Epoch 2014: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5414e-05 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.7865\n","Epoch 2015/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.8709e-06 - accuracy: 1.0000\n","Epoch 2015: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.8155e-06 - accuracy: 1.0000 - val_loss: 1.0667 - val_accuracy: 0.7923\n","Epoch 2016/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2334e-06 - accuracy: 1.0000\n","Epoch 2016: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.1921e-06 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.7894\n","Epoch 2017/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0105e-05 - accuracy: 1.0000\n","Epoch 2017: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0105e-05 - accuracy: 1.0000 - val_loss: 1.0635 - val_accuracy: 0.7909\n","Epoch 2018/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2056e-06 - accuracy: 1.0000\n","Epoch 2018: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2056e-06 - accuracy: 1.0000 - val_loss: 1.0429 - val_accuracy: 0.7879\n","Epoch 2019/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0338e-05 - accuracy: 1.0000\n","Epoch 2019: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0247e-05 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.7894\n","Epoch 2020/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.1987e-05 - accuracy: 1.0000\n","Epoch 2020: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1987e-05 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.7879\n","Epoch 2021/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.8578e-06 - accuracy: 1.0000\n","Epoch 2021: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8578e-06 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.7909\n","Epoch 2022/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6443e-06 - accuracy: 1.0000\n","Epoch 2022: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.5970e-06 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.7894\n","Epoch 2023/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.3002e-06 - accuracy: 1.0000\n","Epoch 2023: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.3002e-06 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.7953\n","Epoch 2024/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.8325e-06 - accuracy: 1.0000\n","Epoch 2024: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8325e-06 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.7953\n","Epoch 2025/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2436e-06 - accuracy: 1.0000\n","Epoch 2025: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.2089e-06 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.7909\n","Epoch 2026/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.1053e-06 - accuracy: 1.0000\n","Epoch 2026: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1053e-06 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.7953\n","Epoch 2027/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9943e-06 - accuracy: 1.0000\n","Epoch 2027: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.9422e-06 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.7923\n","Epoch 2028/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.4039e-06 - accuracy: 1.0000\n","Epoch 2028: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.3694e-06 - accuracy: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.7909\n","Epoch 2029/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3907e-06 - accuracy: 1.0000\n","Epoch 2029: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.3633e-06 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.7923\n","Epoch 2030/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.5768e-06 - accuracy: 1.0000\n","Epoch 2030: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.5768e-06 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.7909\n","Epoch 2031/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.5273e-06 - accuracy: 1.0000\n","Epoch 2031: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.5273e-06 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.7850\n","Epoch 2032/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5147e-05 - accuracy: 1.0000\n","Epoch 2032: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5030e-05 - accuracy: 1.0000 - val_loss: 0.9371 - val_accuracy: 0.7938\n","Epoch 2033/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5590e-06 - accuracy: 1.0000\n","Epoch 2033: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.5037e-06 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.7953\n","Epoch 2034/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3091e-06 - accuracy: 1.0000\n","Epoch 2034: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2717e-06 - accuracy: 1.0000 - val_loss: 1.0115 - val_accuracy: 0.7923\n","Epoch 2035/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0092e-05 - accuracy: 1.0000\n","Epoch 2035: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0006e-05 - accuracy: 1.0000 - val_loss: 1.2112 - val_accuracy: 0.7835\n","Epoch 2036/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.5710e-06 - accuracy: 1.0000\n","Epoch 2036: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.5710e-06 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.7865\n","Epoch 2037/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4358e-05 - accuracy: 1.0000\n","Epoch 2037: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4358e-05 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.7938\n","Epoch 2038/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4011e-06 - accuracy: 1.0000\n","Epoch 2038: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.3721e-06 - accuracy: 1.0000 - val_loss: 0.8861 - val_accuracy: 0.7938\n","Epoch 2039/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6196e-06 - accuracy: 1.0000\n","Epoch 2039: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5957e-06 - accuracy: 1.0000 - val_loss: 0.8878 - val_accuracy: 0.7982\n","Epoch 2040/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.8558e-06 - accuracy: 1.0000\n","Epoch 2040: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.7856e-06 - accuracy: 1.0000 - val_loss: 0.8899 - val_accuracy: 0.8041\n","Epoch 2041/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.7973e-06 - accuracy: 1.0000\n","Epoch 2041: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.7973e-06 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.7938\n","Epoch 2042/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.5831e-06 - accuracy: 1.0000\n","Epoch 2042: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.5831e-06 - accuracy: 1.0000 - val_loss: 0.8874 - val_accuracy: 0.7909\n","Epoch 2043/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4518e-06 - accuracy: 1.0000\n","Epoch 2043: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4220e-06 - accuracy: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.7835\n","Epoch 2044/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2646e-06 - accuracy: 1.0000\n","Epoch 2044: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2646e-06 - accuracy: 1.0000 - val_loss: 0.8935 - val_accuracy: 0.7850\n","Epoch 2045/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1475e-06 - accuracy: 1.0000\n","Epoch 2045: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1475e-06 - accuracy: 1.0000 - val_loss: 0.8736 - val_accuracy: 0.7894\n","Epoch 2046/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5964e-06 - accuracy: 1.0000\n","Epoch 2046: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6869e-06 - accuracy: 1.0000 - val_loss: 0.8654 - val_accuracy: 0.7909\n","Epoch 2047/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.4223e-06 - accuracy: 1.0000\n","Epoch 2047: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.4223e-06 - accuracy: 1.0000 - val_loss: 0.9266 - val_accuracy: 0.8012\n","Epoch 2048/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.9485e-06 - accuracy: 1.0000\n","Epoch 2048: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9485e-06 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.7894\n","Epoch 2049/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4506e-06 - accuracy: 1.0000\n","Epoch 2049: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4553e-06 - accuracy: 1.0000 - val_loss: 0.8847 - val_accuracy: 0.7894\n","Epoch 2050/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8525e-06 - accuracy: 1.0000\n","Epoch 2050: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.8743e-06 - accuracy: 1.0000 - val_loss: 0.8550 - val_accuracy: 0.7997\n","Epoch 2051/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.5853e-07 - accuracy: 1.0000\n","Epoch 2051: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.5317e-07 - accuracy: 1.0000 - val_loss: 0.8706 - val_accuracy: 0.7923\n","Epoch 2052/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5172e-06 - accuracy: 1.0000\n","Epoch 2052: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5013e-06 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.7909\n","Epoch 2053/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7578e-06 - accuracy: 1.0000\n","Epoch 2053: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7360e-06 - accuracy: 1.0000 - val_loss: 0.8503 - val_accuracy: 0.7968\n","Epoch 2054/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.5343e-04 - accuracy: 0.9997\n","Epoch 2054: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.5343e-04 - accuracy: 0.9997 - val_loss: 3.2550 - val_accuracy: 0.5302\n","Epoch 2055/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n","Epoch 2055: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.4481 - val_accuracy: 0.7378\n","Epoch 2056/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6566e-05 - accuracy: 1.0000\n","Epoch 2056: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6566e-05 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.8041\n","Epoch 2057/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9988e-04 - accuracy: 0.9997\n","Epoch 2057: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9543e-04 - accuracy: 0.9997 - val_loss: 1.7560 - val_accuracy: 0.7246\n","Epoch 2058/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988\n","Epoch 2058: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 1.4861 - val_accuracy: 0.7349\n","Epoch 2059/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.1779e-04 - accuracy: 0.9997\n","Epoch 2059: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.1779e-04 - accuracy: 0.9997 - val_loss: 1.2135 - val_accuracy: 0.7688\n","Epoch 2060/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.3826e-05 - accuracy: 1.0000\n","Epoch 2060: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 9.3826e-05 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.7879\n","Epoch 2061/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1611e-04 - accuracy: 1.0000\n","Epoch 2061: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1611e-04 - accuracy: 1.0000 - val_loss: 0.9115 - val_accuracy: 0.8012\n","Epoch 2062/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9907e-05 - accuracy: 1.0000\n","Epoch 2062: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.9555e-05 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.7820\n","Epoch 2063/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9328e-05 - accuracy: 1.0000\n","Epoch 2063: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9328e-05 - accuracy: 1.0000 - val_loss: 1.0217 - val_accuracy: 0.7776\n","Epoch 2064/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.0754e-05 - accuracy: 1.0000\n","Epoch 2064: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.0109e-05 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.7732\n","Epoch 2065/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1930e-04 - accuracy: 1.0000\n","Epoch 2065: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1930e-04 - accuracy: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.7732\n","Epoch 2066/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.1068e-05 - accuracy: 1.0000\n","Epoch 2066: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.0519e-05 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.7997\n","Epoch 2067/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2792e-05 - accuracy: 1.0000\n","Epoch 2067: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2589e-05 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.7923\n","Epoch 2068/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.0728e-06 - accuracy: 1.0000\n","Epoch 2068: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.0728e-06 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.7982\n","Epoch 2069/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4476e-05 - accuracy: 1.0000\n","Epoch 2069: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4345e-05 - accuracy: 1.0000 - val_loss: 0.8965 - val_accuracy: 0.7938\n","Epoch 2070/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.4715e-05 - accuracy: 1.0000\n","Epoch 2070: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.4111e-05 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.7806\n","Epoch 2071/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0490e-05 - accuracy: 1.0000\n","Epoch 2071: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0403e-05 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.7923\n","Epoch 2072/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1220e-05 - accuracy: 1.0000\n","Epoch 2072: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1211e-05 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.7923\n","Epoch 2073/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7047e-05 - accuracy: 1.0000\n","Epoch 2073: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7047e-05 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.7894\n","Epoch 2074/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.7189e-06 - accuracy: 1.0000\n","Epoch 2074: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.7189e-06 - accuracy: 1.0000 - val_loss: 0.8675 - val_accuracy: 0.7909\n","Epoch 2075/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.8555e-06 - accuracy: 1.0000\n","Epoch 2075: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.7707e-06 - accuracy: 1.0000 - val_loss: 0.8514 - val_accuracy: 0.7894\n","Epoch 2076/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.7740e-06 - accuracy: 1.0000\n","Epoch 2076: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.8438e-06 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.7938\n","Epoch 2077/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8925e-06 - accuracy: 1.0000\n","Epoch 2077: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.8925e-06 - accuracy: 1.0000 - val_loss: 0.8682 - val_accuracy: 0.7938\n","Epoch 2078/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.6812e-06 - accuracy: 1.0000\n","Epoch 2078: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.5952e-06 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.7953\n","Epoch 2079/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0577e-05 - accuracy: 1.0000\n","Epoch 2079: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0675e-05 - accuracy: 1.0000 - val_loss: 0.8726 - val_accuracy: 0.7909\n","Epoch 2080/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7235e-05 - accuracy: 1.0000\n","Epoch 2080: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7090e-05 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.7850\n","Epoch 2081/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.0801e-06 - accuracy: 1.0000\n","Epoch 2081: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.0801e-06 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.7909\n","Epoch 2082/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.1122e-05 - accuracy: 1.0000\n","Epoch 2082: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.1122e-05 - accuracy: 1.0000 - val_loss: 1.5075 - val_accuracy: 0.7437\n","Epoch 2083/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.2837e-06 - accuracy: 1.0000\n","Epoch 2083: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.2837e-06 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.7776\n","Epoch 2084/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.5999e-05 - accuracy: 1.0000\n","Epoch 2084: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.5213e-05 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.7865\n","Epoch 2085/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6567e-05 - accuracy: 1.0000\n","Epoch 2085: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6567e-05 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.8012\n","Epoch 2086/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.5768e-05 - accuracy: 1.0000\n","Epoch 2086: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.5442e-05 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.7997\n","Epoch 2087/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5032e-06 - accuracy: 1.0000\n","Epoch 2087: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.4868e-06 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8027\n","Epoch 2088/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.8166e-06 - accuracy: 1.0000\n","Epoch 2088: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.8166e-06 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.8056\n","Epoch 2089/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.6122e-06 - accuracy: 1.0000\n","Epoch 2089: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.5289e-06 - accuracy: 1.0000 - val_loss: 0.7678 - val_accuracy: 0.8041\n","Epoch 2090/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.0847e-06 - accuracy: 1.0000\n","Epoch 2090: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.0847e-06 - accuracy: 1.0000 - val_loss: 0.7476 - val_accuracy: 0.8012\n","Epoch 2091/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.7525e-06 - accuracy: 1.0000\n","Epoch 2091: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.7525e-06 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8041\n","Epoch 2092/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.1434e-05 - accuracy: 1.0000\n","Epoch 2092: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1148e-05 - accuracy: 1.0000 - val_loss: 0.5835 - val_accuracy: 0.8351\n","Epoch 2093/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.9037e-06 - accuracy: 1.0000\n","Epoch 2093: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.9037e-06 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8041\n","Epoch 2094/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3177e-06 - accuracy: 1.0000\n","Epoch 2094: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.2988e-06 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.7997\n","Epoch 2095/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.4077e-06 - accuracy: 1.0000\n","Epoch 2095: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.4077e-06 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.8056\n","Epoch 2096/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.1970e-05 - accuracy: 1.0000\n","Epoch 2096: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1764e-05 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8071\n","Epoch 2097/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7235e-05 - accuracy: 1.0000\n","Epoch 2097: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7235e-05 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.8056\n","Epoch 2098/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1953e-06 - accuracy: 1.0000\n","Epoch 2098: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.1612e-06 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.8041\n","Epoch 2099/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.7952e-06 - accuracy: 1.0000\n","Epoch 2099: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.7952e-06 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.8071\n","Epoch 2100/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9101e-06 - accuracy: 1.0000\n","Epoch 2100: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.8790e-06 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8071\n","Epoch 2101/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.7392e-06 - accuracy: 1.0000\n","Epoch 2101: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.6870e-06 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.8115\n","Epoch 2102/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7922e-06 - accuracy: 1.0000\n","Epoch 2102: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7713e-06 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.8115\n","Epoch 2103/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.4582e-06 - accuracy: 1.0000\n","Epoch 2103: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4582e-06 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8130\n","Epoch 2104/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2184e-06 - accuracy: 1.0000\n","Epoch 2104: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2045e-06 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8144\n","Epoch 2105/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3347e-06 - accuracy: 1.0000\n","Epoch 2105: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3337e-06 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.8159\n","Epoch 2106/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3459e-06 - accuracy: 1.0000\n","Epoch 2106: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3459e-06 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8189\n","Epoch 2107/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.0906e-06 - accuracy: 1.0000\n","Epoch 2107: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.0906e-06 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8159\n","Epoch 2108/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5404e-06 - accuracy: 1.0000\n","Epoch 2108: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5290e-06 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8189\n","Epoch 2109/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6086e-06 - accuracy: 1.0000\n","Epoch 2109: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5864e-06 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.8159\n","Epoch 2110/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.1337e-06 - accuracy: 1.0000\n","Epoch 2110: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.1337e-06 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.8130\n","Epoch 2111/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2450e-06 - accuracy: 1.0000\n","Epoch 2111: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2344e-06 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8174\n","Epoch 2112/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4811e-05 - accuracy: 1.0000\n","Epoch 2112: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4811e-05 - accuracy: 1.0000 - val_loss: 0.7386 - val_accuracy: 0.8027\n","Epoch 2113/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.8324e-06 - accuracy: 1.0000\n","Epoch 2113: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.7823e-06 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8085\n","Epoch 2114/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3841e-06 - accuracy: 1.0000\n","Epoch 2114: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3453e-06 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8130\n","Epoch 2115/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.6004e-06 - accuracy: 1.0000\n","Epoch 2115: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6004e-06 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8174\n","Epoch 2116/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.1885e-06 - accuracy: 1.0000\n","Epoch 2116: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1608e-06 - accuracy: 1.0000 - val_loss: 0.7261 - val_accuracy: 0.8144\n","Epoch 2117/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6172e-06 - accuracy: 1.0000\n","Epoch 2117: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6215e-06 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8115\n","Epoch 2118/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.5516e-06 - accuracy: 1.0000\n","Epoch 2118: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.5246e-06 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8100\n","Epoch 2119/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3981e-06 - accuracy: 1.0000\n","Epoch 2119: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3875e-06 - accuracy: 1.0000 - val_loss: 0.7346 - val_accuracy: 0.8159\n","Epoch 2120/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2077e-06 - accuracy: 1.0000\n","Epoch 2120: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2077e-06 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8189\n","Epoch 2121/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9779e-06 - accuracy: 1.0000\n","Epoch 2121: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.9415e-06 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.8203\n","Epoch 2122/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5715e-06 - accuracy: 1.0000\n","Epoch 2122: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5307e-06 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.8115\n","Epoch 2123/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4047e-06 - accuracy: 1.0000\n","Epoch 2123: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3843e-06 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.8159\n","Epoch 2124/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.2051e-06 - accuracy: 1.0000\n","Epoch 2124: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.1369e-06 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8041\n","Epoch 2125/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0828e-06 - accuracy: 1.0000\n","Epoch 2125: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0799e-06 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.8159\n","Epoch 2126/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4132e-06 - accuracy: 1.0000\n","Epoch 2126: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4015e-06 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8203\n","Epoch 2127/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2034e-06 - accuracy: 1.0000\n","Epoch 2127: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.1756e-06 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.8012\n","Epoch 2128/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0648e-06 - accuracy: 1.0000\n","Epoch 2128: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0648e-06 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8365\n","Epoch 2129/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2362e-06 - accuracy: 1.0000\n","Epoch 2129: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2315e-06 - accuracy: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.8468\n","Epoch 2130/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3243e-06 - accuracy: 1.0000\n","Epoch 2130: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3243e-06 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.8439\n","Epoch 2131/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.1937e-07 - accuracy: 1.0000\n","Epoch 2131: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.1937e-07 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.8439\n","Epoch 2132/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.7538e-07 - accuracy: 1.0000\n","Epoch 2132: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.7012e-07 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.8439\n","Epoch 2133/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5570e-06 - accuracy: 1.0000\n","Epoch 2133: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5437e-06 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.8498\n","Epoch 2134/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6249e-06 - accuracy: 1.0000\n","Epoch 2134: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6249e-06 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.8424\n","Epoch 2135/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3540e-06 - accuracy: 1.0000\n","Epoch 2135: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3382e-06 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.8513\n","Epoch 2136/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9433e-06 - accuracy: 1.0000\n","Epoch 2136: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9045e-06 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.8395\n","Epoch 2137/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.7566e-07 - accuracy: 1.0000\n","Epoch 2137: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.7566e-07 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.8454\n","Epoch 2138/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3121e-06 - accuracy: 1.0000\n","Epoch 2138: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3009e-06 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.8395\n","Epoch 2139/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6485e-07 - accuracy: 1.0000\n","Epoch 2139: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.6148e-07 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.8468\n","Epoch 2140/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1023e-06 - accuracy: 1.0000\n","Epoch 2140: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0931e-06 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8483\n","Epoch 2141/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6071e-07 - accuracy: 1.0000\n","Epoch 2141: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.5717e-07 - accuracy: 1.0000 - val_loss: 0.5563 - val_accuracy: 0.8468\n","Epoch 2142/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.5461e-06 - accuracy: 1.0000\n","Epoch 2142: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.5461e-06 - accuracy: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.8498\n","Epoch 2143/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2300e-06 - accuracy: 1.0000\n","Epoch 2143: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2300e-06 - accuracy: 1.0000 - val_loss: 0.5364 - val_accuracy: 0.8542\n","Epoch 2144/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.8178e-07 - accuracy: 1.0000\n","Epoch 2144: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8178e-07 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.8468\n","Epoch 2145/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2970e-07 - accuracy: 1.0000\n","Epoch 2145: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.2970e-07 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.8424\n","Epoch 2146/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.4494e-07 - accuracy: 1.0000\n","Epoch 2146: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.4494e-07 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.8409\n","Epoch 2147/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0684e-07 - accuracy: 1.0000\n","Epoch 2147: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.0362e-07 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.8395\n","Epoch 2148/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0276e-06 - accuracy: 1.0000\n","Epoch 2148: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0276e-06 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.8365\n","Epoch 2149/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3580e-07 - accuracy: 1.0000\n","Epoch 2149: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.3348e-07 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.8409\n","Epoch 2150/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.0430e-07 - accuracy: 1.0000\n","Epoch 2150: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.0430e-07 - accuracy: 1.0000 - val_loss: 0.5623 - val_accuracy: 0.8439\n","Epoch 2151/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.5688e-07 - accuracy: 1.0000\n","Epoch 2151: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.5688e-07 - accuracy: 1.0000 - val_loss: 0.5646 - val_accuracy: 0.8439\n","Epoch 2152/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7263e-06 - accuracy: 1.0000\n","Epoch 2152: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7114e-06 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.8498\n","Epoch 2153/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2617e-06 - accuracy: 1.0000\n","Epoch 2153: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2617e-06 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.8483\n","Epoch 2154/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9593e-07 - accuracy: 1.0000\n","Epoch 2154: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9282e-07 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.8395\n","Epoch 2155/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.3462e-07 - accuracy: 1.0000\n","Epoch 2155: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.2980e-07 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.8395\n","Epoch 2156/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.2526e-07 - accuracy: 1.0000\n","Epoch 2156: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.2526e-07 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8409\n","Epoch 2157/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1811e-06 - accuracy: 1.0000\n","Epoch 2157: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1811e-06 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.8822\n","Epoch 2158/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1520e-07 - accuracy: 1.0000\n","Epoch 2158: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1520e-07 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.8454\n","Epoch 2159/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5185e-07 - accuracy: 1.0000\n","Epoch 2159: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4637e-07 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.8277\n","Epoch 2160/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2544e-07 - accuracy: 1.0000\n","Epoch 2160: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2544e-07 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.8321\n","Epoch 2161/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.1057e-07 - accuracy: 1.0000\n","Epoch 2161: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.0881e-07 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8336\n","Epoch 2162/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2626e-07 - accuracy: 1.0000\n","Epoch 2162: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2348e-07 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.8233\n","Epoch 2163/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.0811e-07 - accuracy: 1.0000\n","Epoch 2163: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.0811e-07 - accuracy: 1.0000 - val_loss: 0.8631 - val_accuracy: 0.8056\n","Epoch 2164/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.5108e-07 - accuracy: 1.0000\n","Epoch 2164: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.5108e-07 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.8203\n","Epoch 2165/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.2092e-07 - accuracy: 1.0000\n","Epoch 2165: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.7510e-07 - accuracy: 1.0000 - val_loss: 0.9213 - val_accuracy: 0.7953\n","Epoch 2166/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9183e-07 - accuracy: 1.0000\n","Epoch 2166: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.9183e-07 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.8130\n","Epoch 2167/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7135e-07 - accuracy: 1.0000\n","Epoch 2167: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7135e-07 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8233\n","Epoch 2168/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9511e-07 - accuracy: 1.0000\n","Epoch 2168: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.9056e-07 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8247\n","Epoch 2169/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.6596e-07 - accuracy: 1.0000\n","Epoch 2169: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.6168e-07 - accuracy: 1.0000 - val_loss: 0.8509 - val_accuracy: 0.8159\n","Epoch 2170/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.1458e-07 - accuracy: 1.0000\n","Epoch 2170: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.1458e-07 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.8174\n","Epoch 2171/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.9944e-07 - accuracy: 1.0000\n","Epoch 2171: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9944e-07 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8262\n","Epoch 2172/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0482e-06 - accuracy: 1.0000\n","Epoch 2172: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0113e-06 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.7688\n","Epoch 2173/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4094e-06 - accuracy: 1.0000\n","Epoch 2173: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3975e-06 - accuracy: 1.0000 - val_loss: 2.1814 - val_accuracy: 0.7334\n","Epoch 2174/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.9728e-07 - accuracy: 1.0000\n","Epoch 2174: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.9728e-07 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.8233\n","Epoch 2175/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.1564e-07 - accuracy: 1.0000\n","Epoch 2175: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.0823e-07 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.8468\n","Epoch 2176/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3510e-07 - accuracy: 1.0000\n","Epoch 2176: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.3321e-07 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.8557\n","Epoch 2177/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7989e-07 - accuracy: 1.0000\n","Epoch 2177: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7830e-07 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8498\n","Epoch 2178/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2582e-07 - accuracy: 1.0000\n","Epoch 2178: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2582e-07 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.8498\n","Epoch 2179/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2038e-05 - accuracy: 1.0000\n","Epoch 2179: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.1385e-05 - accuracy: 1.0000 - val_loss: 1.8058 - val_accuracy: 0.6082\n","Epoch 2180/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9994\n","Epoch 2180: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 5.2330 - val_accuracy: 0.4904\n","Epoch 2181/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9991\n","Epoch 2181: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 2.0087 - val_accuracy: 0.6642\n","Epoch 2182/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9994\n","Epoch 2182: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 2.5158 - val_accuracy: 0.6421\n","Epoch 2183/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.4260e-05 - accuracy: 1.0000\n","Epoch 2183: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.3462e-05 - accuracy: 1.0000 - val_loss: 1.2354 - val_accuracy: 0.7747\n","Epoch 2184/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.1191e-05 - accuracy: 1.0000\n","Epoch 2184: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0636e-05 - accuracy: 1.0000 - val_loss: 0.9435 - val_accuracy: 0.7894\n","Epoch 2185/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.4875e-05 - accuracy: 1.0000\n","Epoch 2185: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4875e-05 - accuracy: 1.0000 - val_loss: 0.9528 - val_accuracy: 0.7835\n","Epoch 2186/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6088e-05 - accuracy: 1.0000\n","Epoch 2186: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5849e-05 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.7909\n","Epoch 2187/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4345e-05 - accuracy: 1.0000\n","Epoch 2187: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4123e-05 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.7894\n","Epoch 2188/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7408e-05 - accuracy: 1.0000\n","Epoch 2188: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7290e-05 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.7982\n","Epoch 2189/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4791e-05 - accuracy: 1.0000\n","Epoch 2189: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4768e-05 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.7953\n","Epoch 2190/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6608e-06 - accuracy: 1.0000\n","Epoch 2190: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.6290e-06 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.7982\n","Epoch 2191/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3245e-05 - accuracy: 1.0000\n","Epoch 2191: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3245e-05 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.7997\n","Epoch 2192/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.9247e-05 - accuracy: 1.0000\n","Epoch 2192: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.8621e-05 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8277\n","Epoch 2193/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7508e-05 - accuracy: 1.0000\n","Epoch 2193: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7289e-05 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.8174\n","Epoch 2194/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5466e-06 - accuracy: 1.0000\n","Epoch 2194: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5329e-06 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8115\n","Epoch 2195/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4734e-06 - accuracy: 1.0000\n","Epoch 2195: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.4734e-06 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.8115\n","Epoch 2196/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.2953e-06 - accuracy: 1.0000\n","Epoch 2196: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.2953e-06 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8100\n","Epoch 2197/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.1446e-06 - accuracy: 1.0000\n","Epoch 2197: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.0877e-06 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.8041\n","Epoch 2198/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.4690e-06 - accuracy: 1.0000\n","Epoch 2198: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.4045e-06 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8130\n","Epoch 2199/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.6884e-06 - accuracy: 1.0000\n","Epoch 2199: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.6091e-06 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.8144\n","Epoch 2200/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7206e-05 - accuracy: 1.0000\n","Epoch 2200: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7055e-05 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.8174\n","Epoch 2201/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.7260e-06 - accuracy: 1.0000\n","Epoch 2201: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.7603e-06 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.8203\n","Epoch 2202/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0005e-05 - accuracy: 1.0000\n","Epoch 2202: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9838e-05 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8100\n","Epoch 2203/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.9391e-06 - accuracy: 1.0000\n","Epoch 2203: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9391e-06 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8115\n","Epoch 2204/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7379e-06 - accuracy: 1.0000\n","Epoch 2204: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7205e-06 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8130\n","Epoch 2205/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.3126e-06 - accuracy: 1.0000\n","Epoch 2205: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3126e-06 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.8144\n","Epoch 2206/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2123e-06 - accuracy: 1.0000\n","Epoch 2206: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 6s 49ms/step - loss: 7.1577e-06 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8159\n","Epoch 2207/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.0863e-06 - accuracy: 1.0000\n","Epoch 2207: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.0863e-06 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.8218\n","Epoch 2208/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.0314e-06 - accuracy: 1.0000\n","Epoch 2208: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.9806e-06 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8174\n","Epoch 2209/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.6877e-06 - accuracy: 1.0000\n","Epoch 2209: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.6174e-06 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8203\n","Epoch 2210/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8821e-06 - accuracy: 1.0000\n","Epoch 2210: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.8740e-06 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8262\n","Epoch 2211/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.0928e-06 - accuracy: 1.0000\n","Epoch 2211: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0928e-06 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8218\n","Epoch 2212/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3201e-06 - accuracy: 1.0000\n","Epoch 2212: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.3497e-06 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8203\n","Epoch 2213/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6671e-06 - accuracy: 1.0000\n","Epoch 2213: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6671e-06 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8203\n","Epoch 2214/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3743e-05 - accuracy: 1.0000\n","Epoch 2214: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.3433e-05 - accuracy: 1.0000 - val_loss: 0.7708 - val_accuracy: 0.8056\n","Epoch 2215/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.3896e-06 - accuracy: 1.0000\n","Epoch 2215: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.3896e-06 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.8041\n","Epoch 2216/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.9043e-06 - accuracy: 1.0000\n","Epoch 2216: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.9043e-06 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.7997\n","Epoch 2217/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1926e-06 - accuracy: 1.0000\n","Epoch 2217: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1926e-06 - accuracy: 1.0000 - val_loss: 0.7794 - val_accuracy: 0.7968\n","Epoch 2218/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0148e-06 - accuracy: 1.0000\n","Epoch 2218: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9825e-06 - accuracy: 1.0000 - val_loss: 0.7835 - val_accuracy: 0.7968\n","Epoch 2219/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7666e-06 - accuracy: 1.0000\n","Epoch 2219: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7666e-06 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.7968\n","Epoch 2220/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.0951e-06 - accuracy: 1.0000\n","Epoch 2220: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0951e-06 - accuracy: 1.0000 - val_loss: 0.7864 - val_accuracy: 0.7982\n","Epoch 2221/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.6550e-05 - accuracy: 1.0000\n","Epoch 2221: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.6029e-05 - accuracy: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.7820\n","Epoch 2222/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0303e-05 - accuracy: 1.0000\n","Epoch 2222: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0303e-05 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.8262\n","Epoch 2223/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4232e-04 - accuracy: 1.0000\n","Epoch 2223: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4102e-04 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.7452\n","Epoch 2224/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9696e-04 - accuracy: 1.0000\n","Epoch 2224: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9514e-04 - accuracy: 1.0000 - val_loss: 0.7775 - val_accuracy: 0.7599\n","Epoch 2225/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8192e-06 - accuracy: 1.0000\n","Epoch 2225: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.8192e-06 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.8616\n","Epoch 2226/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6693e-05 - accuracy: 1.0000\n","Epoch 2226: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6541e-05 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8733\n","Epoch 2227/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.9153e-06 - accuracy: 1.0000\n","Epoch 2227: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.9153e-06 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.8630\n","Epoch 2228/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.3471e-06 - accuracy: 1.0000\n","Epoch 2228: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 6s 49ms/step - loss: 8.3471e-06 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.8616\n","Epoch 2229/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.1992e-05 - accuracy: 1.0000\n","Epoch 2229: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.1992e-05 - accuracy: 1.0000 - val_loss: 1.6190 - val_accuracy: 0.7644\n","Epoch 2230/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.4775e-05 - accuracy: 1.0000\n","Epoch 2230: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.4103e-05 - accuracy: 1.0000 - val_loss: 2.3423 - val_accuracy: 0.6834\n","Epoch 2231/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2570e-06 - accuracy: 1.0000\n","Epoch 2231: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2306e-06 - accuracy: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.7835\n","Epoch 2232/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8804e-06 - accuracy: 1.0000\n","Epoch 2232: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8551e-06 - accuracy: 1.0000 - val_loss: 0.8470 - val_accuracy: 0.8041\n","Epoch 2233/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.6348e-06 - accuracy: 1.0000\n","Epoch 2233: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.6348e-06 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.8115\n","Epoch 2234/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0499e-05 - accuracy: 1.0000\n","Epoch 2234: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0328e-05 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8218\n","Epoch 2235/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.2670e-06 - accuracy: 1.0000\n","Epoch 2235: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 49ms/step - loss: 5.2670e-06 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8159\n","Epoch 2236/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7529e-06 - accuracy: 1.0000\n","Epoch 2236: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7529e-06 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8203\n","Epoch 2237/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4004e-06 - accuracy: 1.0000\n","Epoch 2237: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4004e-06 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8189\n","Epoch 2238/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3648e-05 - accuracy: 1.0000\n","Epoch 2238: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.3244e-05 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 0.7879\n","Epoch 2239/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1279e-05 - accuracy: 1.0000\n","Epoch 2239: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1279e-05 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.8041\n","Epoch 2240/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6049e-04 - accuracy: 1.0000\n","Epoch 2240: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5902e-04 - accuracy: 1.0000 - val_loss: 0.8278 - val_accuracy: 0.7644\n","Epoch 2241/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.6347e-04 - accuracy: 0.9997\n","Epoch 2241: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.6347e-04 - accuracy: 0.9997 - val_loss: 3.4506 - val_accuracy: 0.4757\n","Epoch 2242/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9062e-05 - accuracy: 1.0000\n","Epoch 2242: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8536e-05 - accuracy: 1.0000 - val_loss: 0.9263 - val_accuracy: 0.7496\n","Epoch 2243/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4031e-05 - accuracy: 1.0000\n","Epoch 2243: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4031e-05 - accuracy: 1.0000 - val_loss: 0.9188 - val_accuracy: 0.7585\n","Epoch 2244/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1641e-05 - accuracy: 1.0000\n","Epoch 2244: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1641e-05 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.8056\n","Epoch 2245/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6550e-05 - accuracy: 1.0000\n","Epoch 2245: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.5949e-05 - accuracy: 1.0000 - val_loss: 0.9422 - val_accuracy: 0.7923\n","Epoch 2246/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8592e-05 - accuracy: 1.0000\n","Epoch 2246: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8424e-05 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.8424\n","Epoch 2247/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4376e-05 - accuracy: 1.0000\n","Epoch 2247: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4154e-05 - accuracy: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8571\n","Epoch 2248/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4691e-05 - accuracy: 1.0000\n","Epoch 2248: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4691e-05 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.8395\n","Epoch 2249/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3563e-06 - accuracy: 1.0000\n","Epoch 2249: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3561e-06 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.8498\n","Epoch 2250/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5928e-05 - accuracy: 1.0000\n","Epoch 2250: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5785e-05 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.8454\n","Epoch 2251/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4755e-06 - accuracy: 1.0000\n","Epoch 2251: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4607e-06 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.8513\n","Epoch 2252/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3386e-06 - accuracy: 1.0000\n","Epoch 2252: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3371e-06 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.8542\n","Epoch 2253/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1500e-06 - accuracy: 1.0000\n","Epoch 2253: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1500e-06 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.8557\n","Epoch 2254/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.1370e-06 - accuracy: 1.0000\n","Epoch 2254: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1370e-06 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.8513\n","Epoch 2255/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5809e-06 - accuracy: 1.0000\n","Epoch 2255: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5809e-06 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8513\n","Epoch 2256/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3836e-06 - accuracy: 1.0000\n","Epoch 2256: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3734e-06 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8513\n","Epoch 2257/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3075e-06 - accuracy: 1.0000\n","Epoch 2257: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2841e-06 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8498\n","Epoch 2258/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0581e-06 - accuracy: 1.0000\n","Epoch 2258: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0527e-06 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8498\n","Epoch 2259/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0380e-06 - accuracy: 1.0000\n","Epoch 2259: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0233e-06 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.8498\n","Epoch 2260/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.7001e-06 - accuracy: 1.0000\n","Epoch 2260: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 6.7001e-06 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8616\n","Epoch 2261/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.8039e-07 - accuracy: 1.0000\n","Epoch 2261: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.1908e-07 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.8498\n","Epoch 2262/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7601e-06 - accuracy: 1.0000\n","Epoch 2262: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7601e-06 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.8557\n","Epoch 2263/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2867e-06 - accuracy: 1.0000\n","Epoch 2263: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2771e-06 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8527\n","Epoch 2264/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5095e-06 - accuracy: 1.0000\n","Epoch 2264: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.4893e-06 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.8498\n","Epoch 2265/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7278e-06 - accuracy: 1.0000\n","Epoch 2265: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7130e-06 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.8498\n","Epoch 2266/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.1547e-07 - accuracy: 1.0000\n","Epoch 2266: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.1367e-07 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8513\n","Epoch 2267/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.6354e-07 - accuracy: 1.0000\n","Epoch 2267: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.5930e-07 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8513\n","Epoch 2268/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.9984e-06 - accuracy: 1.0000\n","Epoch 2268: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.9984e-06 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8675\n","Epoch 2269/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7854e-06 - accuracy: 1.0000\n","Epoch 2269: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7854e-06 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.8571\n","Epoch 2270/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.2372e-06 - accuracy: 1.0000\n","Epoch 2270: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1991e-06 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.8409\n","Epoch 2271/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.4060e-06 - accuracy: 1.0000\n","Epoch 2271: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.3295e-06 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.8409\n","Epoch 2272/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8329e-06 - accuracy: 1.0000\n","Epoch 2272: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.8104e-06 - accuracy: 1.0000 - val_loss: 0.5557 - val_accuracy: 0.8424\n","Epoch 2273/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7839e-06 - accuracy: 1.0000\n","Epoch 2273: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7839e-06 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.8351\n","Epoch 2274/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2304e-06 - accuracy: 1.0000\n","Epoch 2274: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2193e-06 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.8336\n","Epoch 2275/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3217e-06 - accuracy: 1.0000\n","Epoch 2275: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3131e-06 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.8321\n","Epoch 2276/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9135e-06 - accuracy: 1.0000\n","Epoch 2276: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9135e-06 - accuracy: 1.0000 - val_loss: 0.5432 - val_accuracy: 0.8365\n","Epoch 2277/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8358e-06 - accuracy: 1.0000\n","Epoch 2277: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.8441e-06 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8321\n","Epoch 2278/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5268e-06 - accuracy: 1.0000\n","Epoch 2278: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5172e-06 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.8351\n","Epoch 2279/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2199e-06 - accuracy: 1.0000\n","Epoch 2279: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2018e-06 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.8380\n","Epoch 2280/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2321e-06 - accuracy: 1.0000\n","Epoch 2280: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2221e-06 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.8321\n","Epoch 2281/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1880e-05 - accuracy: 1.0000\n","Epoch 2281: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1880e-05 - accuracy: 1.0000 - val_loss: 1.0041 - val_accuracy: 0.7614\n","Epoch 2282/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.2498e-04 - accuracy: 0.9997\n","Epoch 2282: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 6.1919e-04 - accuracy: 0.9997 - val_loss: 2.5310 - val_accuracy: 0.6377\n","Epoch 2283/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.1681e-06 - accuracy: 1.0000\n","Epoch 2283: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.1681e-06 - accuracy: 1.0000 - val_loss: 0.7774 - val_accuracy: 0.7938\n","Epoch 2284/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1557e-05 - accuracy: 1.0000\n","Epoch 2284: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1465e-05 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.7865\n","Epoch 2285/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.3563e-06 - accuracy: 1.0000\n","Epoch 2285: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.2884e-06 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.7850\n","Epoch 2286/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7353e-05 - accuracy: 1.0000\n","Epoch 2286: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7308e-05 - accuracy: 1.0000 - val_loss: 0.7916 - val_accuracy: 0.7850\n","Epoch 2287/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2298e-06 - accuracy: 1.0000\n","Epoch 2287: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 5.1959e-06 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8056\n","Epoch 2288/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2460e-06 - accuracy: 1.0000\n","Epoch 2288: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.2881e-06 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.8115\n","Epoch 2289/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4669e-06 - accuracy: 1.0000\n","Epoch 2289: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4669e-06 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.8174\n","Epoch 2290/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.2442e-06 - accuracy: 1.0000\n","Epoch 2290: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 5.2442e-06 - accuracy: 1.0000 - val_loss: 0.6423 - val_accuracy: 0.8115\n","Epoch 2291/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2042e-05 - accuracy: 1.0000\n","Epoch 2291: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.2042e-05 - accuracy: 1.0000 - val_loss: 1.6849 - val_accuracy: 0.6510\n","Epoch 2292/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5389e-04 - accuracy: 1.0000\n","Epoch 2292: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5247e-04 - accuracy: 1.0000 - val_loss: 3.2784 - val_accuracy: 0.5700\n","Epoch 2293/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9853e-05 - accuracy: 1.0000\n","Epoch 2293: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.9393e-05 - accuracy: 1.0000 - val_loss: 0.8842 - val_accuracy: 0.8085\n","Epoch 2294/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8142e-06 - accuracy: 1.0000\n","Epoch 2294: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.8015e-06 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.8527\n","Epoch 2295/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.0180e-06 - accuracy: 1.0000\n","Epoch 2295: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0180e-06 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8689\n","Epoch 2296/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6647e-06 - accuracy: 1.0000\n","Epoch 2296: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6520e-06 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.8763\n","Epoch 2297/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.9711e-06 - accuracy: 1.0000\n","Epoch 2297: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9711e-06 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8778\n","Epoch 2298/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.7327e-06 - accuracy: 1.0000\n","Epoch 2298: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.7327e-06 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.8792\n","Epoch 2299/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.1729e-07 - accuracy: 1.0000\n","Epoch 2299: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.1462e-07 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8778\n","Epoch 2300/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8483e-06 - accuracy: 1.0000\n","Epoch 2300: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.8321e-06 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8792\n","Epoch 2301/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3962e-06 - accuracy: 1.0000\n","Epoch 2301: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3844e-06 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.8748\n","Epoch 2302/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1120e-06 - accuracy: 1.0000\n","Epoch 2302: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1120e-06 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.8763\n","Epoch 2303/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.6362e-07 - accuracy: 1.0000\n","Epoch 2303: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 8.6362e-07 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.8748\n","Epoch 2304/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9218e-06 - accuracy: 1.0000\n","Epoch 2304: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9218e-06 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.8792\n","Epoch 2305/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7051e-06 - accuracy: 1.0000\n","Epoch 2305: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6905e-06 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.8778\n","Epoch 2306/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3562e-06 - accuracy: 1.0000\n","Epoch 2306: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3438e-06 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.8763\n","Epoch 2307/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5940e-06 - accuracy: 1.0000\n","Epoch 2307: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5797e-06 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.8719\n","Epoch 2308/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.4584e-07 - accuracy: 1.0000\n","Epoch 2308: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 9.4584e-07 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8778\n","Epoch 2309/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9328e-06 - accuracy: 1.0000\n","Epoch 2309: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.8895e-06 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8645\n","Epoch 2310/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.2420e-07 - accuracy: 1.0000\n","Epoch 2310: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2174e-07 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8675\n","Epoch 2311/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.0636e-07 - accuracy: 1.0000\n","Epoch 2311: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 4.0298e-07 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.8675\n","Epoch 2312/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8760e-07 - accuracy: 1.0000\n","Epoch 2312: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.8760e-07 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8689\n","Epoch 2313/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3369e-06 - accuracy: 1.0000\n","Epoch 2313: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3247e-06 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8704\n","Epoch 2314/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.6884e-07 - accuracy: 1.0000\n","Epoch 2314: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 7.7221e-07 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.8704\n","Epoch 2315/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.7104e-07 - accuracy: 1.0000\n","Epoch 2315: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 8.6366e-07 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.8733\n","Epoch 2316/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.6908e-07 - accuracy: 1.0000\n","Epoch 2316: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 9.6090e-07 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.8704\n","Epoch 2317/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0038e-06 - accuracy: 1.0000\n","Epoch 2317: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0038e-06 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.8719\n","Epoch 2318/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.0168e-07 - accuracy: 1.0000\n","Epoch 2318: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9714e-07 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.8719\n","Epoch 2319/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.3177e-06 - accuracy: 1.0000\n","Epoch 2319: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 7.3177e-06 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8763\n","Epoch 2320/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5191e-05 - accuracy: 1.0000\n","Epoch 2320: val_accuracy did not improve from 0.89249\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5191e-05 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.8895\n","Epoch 2321/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.7913e-06 - accuracy: 1.0000\n","Epoch 2321: val_accuracy improved from 0.89249 to 0.89838, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 10s 88ms/step - loss: 2.7697e-06 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8984\n","Epoch 2322/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7188e-06 - accuracy: 1.0000\n","Epoch 2322: val_accuracy improved from 0.89838 to 0.89985, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 7s 60ms/step - loss: 1.7176e-06 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.8999\n","Epoch 2323/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9662e-06 - accuracy: 1.0000\n","Epoch 2323: val_accuracy did not improve from 0.89985\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9494e-06 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.8954\n","Epoch 2324/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.0404e-07 - accuracy: 1.0000\n","Epoch 2324: val_accuracy did not improve from 0.89985\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0180e-07 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.8969\n","Epoch 2325/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2888e-06 - accuracy: 1.0000\n","Epoch 2325: val_accuracy did not improve from 0.89985\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2888e-06 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.8969\n","Epoch 2326/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9822e-06 - accuracy: 1.0000\n","Epoch 2326: val_accuracy improved from 0.89985 to 0.90280, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 10s 87ms/step - loss: 1.9733e-06 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9028\n","Epoch 2327/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2465e-06 - accuracy: 1.0000\n","Epoch 2327: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2353e-06 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.8999\n","Epoch 2328/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.8187e-06 - accuracy: 1.0000\n","Epoch 2328: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 48ms/step - loss: 2.7934e-06 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.8984\n","Epoch 2329/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.7458e-07 - accuracy: 1.0000\n","Epoch 2329: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 48ms/step - loss: 4.7049e-07 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.8969\n","Epoch 2330/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.4042e-07 - accuracy: 1.0000\n","Epoch 2330: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 6.3469e-07 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8954\n","Epoch 2331/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.9017e-07 - accuracy: 1.0000\n","Epoch 2331: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 48ms/step - loss: 5.9017e-07 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8954\n","Epoch 2332/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5442e-06 - accuracy: 1.0000\n","Epoch 2332: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5442e-06 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.8999\n","Epoch 2333/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.9763e-06 - accuracy: 1.0000\n","Epoch 2333: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9763e-06 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8940\n","Epoch 2334/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.3204e-07 - accuracy: 1.0000\n","Epoch 2334: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 3.3065e-07 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.8954\n","Epoch 2335/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6668e-06 - accuracy: 1.0000\n","Epoch 2335: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6668e-06 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.8940\n","Epoch 2336/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5730e-06 - accuracy: 1.0000\n","Epoch 2336: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5626e-06 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.8940\n","Epoch 2337/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.6385e-07 - accuracy: 1.0000\n","Epoch 2337: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 48ms/step - loss: 5.6385e-07 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.8999\n","Epoch 2338/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.3705e-07 - accuracy: 1.0000\n","Epoch 2338: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 7.3040e-07 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9013\n","Epoch 2339/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3552e-06 - accuracy: 1.0000\n","Epoch 2339: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3552e-06 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9028\n","Epoch 2340/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.6232e-07 - accuracy: 1.0000\n","Epoch 2340: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 48ms/step - loss: 5.6232e-07 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9028\n","Epoch 2341/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6446e-07 - accuracy: 1.0000\n","Epoch 2341: val_accuracy did not improve from 0.90280\n","108/108 [==============================] - 5s 47ms/step - loss: 2.6222e-07 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9028\n","Epoch 2342/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.5633e-07 - accuracy: 1.0000\n","Epoch 2342: val_accuracy improved from 0.90280 to 0.90427, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 10s 90ms/step - loss: 3.5358e-07 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9043\n","Epoch 2343/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.5680e-07 - accuracy: 1.0000\n","Epoch 2343: val_accuracy improved from 0.90427 to 0.90574, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 7s 61ms/step - loss: 6.5680e-07 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9057\n","Epoch 2344/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6233e-07 - accuracy: 1.0000\n","Epoch 2344: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 48ms/step - loss: 2.6163e-07 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9043\n","Epoch 2345/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.7767e-07 - accuracy: 1.0000\n","Epoch 2345: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 48ms/step - loss: 5.7236e-07 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9028\n","Epoch 2346/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2454e-06 - accuracy: 1.0000\n","Epoch 2346: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2454e-06 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9028\n","Epoch 2347/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9952e-07 - accuracy: 1.0000\n","Epoch 2347: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 48ms/step - loss: 3.0620e-07 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9028\n","Epoch 2348/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.7099e-07 - accuracy: 1.0000\n","Epoch 2348: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 47ms/step - loss: 3.6759e-07 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.8969\n","Epoch 2349/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4256e-07 - accuracy: 1.0000\n","Epoch 2349: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4066e-07 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.8954\n","Epoch 2350/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9358e-07 - accuracy: 1.0000\n","Epoch 2350: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8822e-07 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.8954\n","Epoch 2351/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.0187e-07 - accuracy: 1.0000\n","Epoch 2351: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9795e-07 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.8954\n","Epoch 2352/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2388e-07 - accuracy: 1.0000\n","Epoch 2352: val_accuracy did not improve from 0.90574\n","108/108 [==============================] - 5s 47ms/step - loss: 5.4021e-07 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.8925\n","Epoch 2353/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1363e-06 - accuracy: 1.0000\n","Epoch 2353: val_accuracy improved from 0.90574 to 0.91163, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 10s 92ms/step - loss: 1.1363e-06 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9116\n","Epoch 2354/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.6358e-07 - accuracy: 1.0000\n","Epoch 2354: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.6071e-07 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.8999\n","Epoch 2355/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.9886e-07 - accuracy: 1.0000\n","Epoch 2355: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.9886e-07 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.8837\n","Epoch 2356/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.7402e-07 - accuracy: 1.0000\n","Epoch 2356: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 6s 49ms/step - loss: 7.6706e-07 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.8881\n","Epoch 2357/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5888e-06 - accuracy: 1.0000\n","Epoch 2357: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5888e-06 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.8910\n","Epoch 2358/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.0381e-07 - accuracy: 1.0000\n","Epoch 2358: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0667e-07 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.8999\n","Epoch 2359/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.2084e-07 - accuracy: 1.0000\n","Epoch 2359: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.1870e-07 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.8895\n","Epoch 2360/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.4087e-07 - accuracy: 1.0000\n","Epoch 2360: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.3782e-07 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.8866\n","Epoch 2361/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3831e-07 - accuracy: 1.0000\n","Epoch 2361: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 2.3831e-07 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.8851\n","Epoch 2362/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.2597e-06 - accuracy: 1.0000\n","Epoch 2362: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 8.5975e-06 - accuracy: 1.0000 - val_loss: 1.3581 - val_accuracy: 0.7437\n","Epoch 2363/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.5946e-04 - accuracy: 0.9997\n","Epoch 2363: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 9.5946e-04 - accuracy: 0.9997 - val_loss: 2.9080 - val_accuracy: 0.6186\n","Epoch 2364/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2163e-05 - accuracy: 1.0000\n","Epoch 2364: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.2163e-05 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.8306\n","Epoch 2365/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2378e-05 - accuracy: 1.0000\n","Epoch 2365: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 46ms/step - loss: 5.1925e-05 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.8277\n","Epoch 2366/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6375e-05 - accuracy: 1.0000\n","Epoch 2366: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.6136e-05 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.8601\n","Epoch 2367/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.3216e-06 - accuracy: 1.0000\n","Epoch 2367: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.3216e-06 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.8704\n","Epoch 2368/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6015e-05 - accuracy: 1.0000\n","Epoch 2368: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5870e-05 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8866\n","Epoch 2369/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.1989e-05 - accuracy: 1.0000\n","Epoch 2369: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 3.1693e-05 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8792\n","Epoch 2370/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.1467e-05 - accuracy: 1.0000\n","Epoch 2370: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1222e-05 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.8498\n","Epoch 2371/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1036e-04 - accuracy: 1.0000\n","Epoch 2371: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0934e-04 - accuracy: 1.0000 - val_loss: 0.7645 - val_accuracy: 0.8085\n","Epoch 2372/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4839e-06 - accuracy: 1.0000\n","Epoch 2372: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 5.4420e-06 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.8616\n","Epoch 2373/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.6897e-06 - accuracy: 1.0000\n","Epoch 2373: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 7.6897e-06 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8616\n","Epoch 2374/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.2337e-05 - accuracy: 1.0000\n","Epoch 2374: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 5.2337e-05 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.8351\n","Epoch 2375/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.7101e-06 - accuracy: 1.0000\n","Epoch 2375: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 6.6522e-06 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.8380\n","Epoch 2376/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0611e-06 - accuracy: 1.0000\n","Epoch 2376: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0450e-06 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.8409\n","Epoch 2377/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.9232e-06 - accuracy: 1.0000\n","Epoch 2377: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9232e-06 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.8424\n","Epoch 2378/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.2932e-05 - accuracy: 1.0000\n","Epoch 2378: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 5.2442e-05 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.8925\n","Epoch 2379/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.6842e-06 - accuracy: 1.0000\n","Epoch 2379: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 7.6398e-06 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.8719\n","Epoch 2380/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2097e-05 - accuracy: 1.0000\n","Epoch 2380: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1987e-05 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.8748\n","Epoch 2381/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.0979e-06 - accuracy: 1.0000\n","Epoch 2381: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 5.0514e-06 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.8837\n","Epoch 2382/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.6378e-06 - accuracy: 1.0000\n","Epoch 2382: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.6135e-06 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.8866\n","Epoch 2383/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.0936e-06 - accuracy: 1.0000\n","Epoch 2383: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.0393e-06 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.8807\n","Epoch 2384/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.8751e-06 - accuracy: 1.0000\n","Epoch 2384: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.8521e-06 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.8866\n","Epoch 2385/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.7740e-06 - accuracy: 1.0000\n","Epoch 2385: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.7327e-06 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.8822\n","Epoch 2386/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6591e-06 - accuracy: 1.0000\n","Epoch 2386: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6453e-06 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.8792\n","Epoch 2387/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7484e-06 - accuracy: 1.0000\n","Epoch 2387: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7484e-06 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.8822\n","Epoch 2388/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4102e-06 - accuracy: 1.0000\n","Epoch 2388: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4102e-06 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.8822\n","Epoch 2389/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.5197e-07 - accuracy: 1.0000\n","Epoch 2389: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.4986e-07 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.8822\n","Epoch 2390/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.3215e-07 - accuracy: 1.0000\n","Epoch 2390: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 8.2717e-07 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.8822\n","Epoch 2391/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.8633e-06 - accuracy: 1.0000\n","Epoch 2391: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.8287e-06 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.8763\n","Epoch 2392/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2113e-06 - accuracy: 1.0000\n","Epoch 2392: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2011e-06 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8807\n","Epoch 2393/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.3814e-07 - accuracy: 1.0000\n","Epoch 2393: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 8.3179e-07 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.8837\n","Epoch 2394/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0097e-06 - accuracy: 1.0000\n","Epoch 2394: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0009e-06 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.8837\n","Epoch 2395/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.8666e-06 - accuracy: 1.0000\n","Epoch 2395: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8666e-06 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.8851\n","Epoch 2396/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.1765e-07 - accuracy: 1.0000\n","Epoch 2396: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 5.1389e-07 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.8837\n","Epoch 2397/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1475e-06 - accuracy: 1.0000\n","Epoch 2397: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1791e-06 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.8822\n","Epoch 2398/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8596e-06 - accuracy: 1.0000\n","Epoch 2398: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.8431e-06 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8822\n","Epoch 2399/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0782e-06 - accuracy: 1.0000\n","Epoch 2399: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0782e-06 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.8851\n","Epoch 2400/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4202e-06 - accuracy: 1.0000\n","Epoch 2400: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4202e-06 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.8792\n","Epoch 2401/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.2755e-07 - accuracy: 1.0000\n","Epoch 2401: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 8.2196e-07 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.8792\n","Epoch 2402/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3548e-05 - accuracy: 1.0000\n","Epoch 2402: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3425e-05 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.8748\n","Epoch 2403/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2126e-06 - accuracy: 1.0000\n","Epoch 2403: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2077e-06 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9028\n","Epoch 2404/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.0379e-07 - accuracy: 1.0000\n","Epoch 2404: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 7.9803e-07 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.8895\n","Epoch 2405/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1893e-06 - accuracy: 1.0000\n","Epoch 2405: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1700e-06 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.8881\n","Epoch 2406/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.5492e-07 - accuracy: 1.0000\n","Epoch 2406: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 9.5492e-07 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.8851\n","Epoch 2407/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3860e-06 - accuracy: 1.0000\n","Epoch 2407: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3798e-06 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8925\n","Epoch 2408/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8768e-07 - accuracy: 1.0000\n","Epoch 2408: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 8.8768e-07 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.8851\n","Epoch 2409/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9512e-06 - accuracy: 1.0000\n","Epoch 2409: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.9160e-06 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.8837\n","Epoch 2410/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.3456e-06 - accuracy: 1.0000\n","Epoch 2410: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3456e-06 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.8778\n","Epoch 2411/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9589e-07 - accuracy: 1.0000\n","Epoch 2411: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9168e-07 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.8822\n","Epoch 2412/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4347e-06 - accuracy: 1.0000\n","Epoch 2412: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4132e-06 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.8748\n","Epoch 2413/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4806e-07 - accuracy: 1.0000\n","Epoch 2413: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 3.4806e-07 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.8822\n","Epoch 2414/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1638e-06 - accuracy: 1.0000\n","Epoch 2414: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1634e-06 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.8851\n","Epoch 2415/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.0397e-07 - accuracy: 1.0000\n","Epoch 2415: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 9.0397e-07 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.8851\n","Epoch 2416/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.5292e-07 - accuracy: 1.0000\n","Epoch 2416: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 9.4492e-07 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8895\n","Epoch 2417/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.3675e-07 - accuracy: 1.0000\n","Epoch 2417: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 4.3675e-07 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8881\n","Epoch 2418/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.2364e-07 - accuracy: 1.0000\n","Epoch 2418: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.2364e-07 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.8925\n","Epoch 2419/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.8233e-07 - accuracy: 1.0000\n","Epoch 2419: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 7.7519e-07 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.8940\n","Epoch 2420/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6776e-07 - accuracy: 1.0000\n","Epoch 2420: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7070e-07 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.8940\n","Epoch 2421/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4603e-06 - accuracy: 1.0000\n","Epoch 2421: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4494e-06 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.8807\n","Epoch 2422/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6853e-06 - accuracy: 1.0000\n","Epoch 2422: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.6653e-06 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.8837\n","Epoch 2423/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.2377e-07 - accuracy: 1.0000\n","Epoch 2423: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2029e-07 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8954\n","Epoch 2424/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3068e-07 - accuracy: 1.0000\n","Epoch 2424: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2735e-07 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.8940\n","Epoch 2425/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.8295e-07 - accuracy: 1.0000\n","Epoch 2425: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 5.7765e-07 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.8940\n","Epoch 2426/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.7797e-07 - accuracy: 1.0000\n","Epoch 2426: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7797e-07 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.8925\n","Epoch 2427/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.9608e-06 - accuracy: 1.0000\n","Epoch 2427: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9608e-06 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.8675\n","Epoch 2428/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5198e-06 - accuracy: 1.0000\n","Epoch 2428: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.5198e-06 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.8630\n","Epoch 2429/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.9930e-07 - accuracy: 1.0000\n","Epoch 2429: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 4.9603e-07 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8483\n","Epoch 2430/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.5805e-06 - accuracy: 1.0000\n","Epoch 2430: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 4.5805e-06 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8144\n","Epoch 2431/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5759e-07 - accuracy: 1.0000\n","Epoch 2431: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5759e-07 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8468\n","Epoch 2432/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.9953e-06 - accuracy: 1.0000\n","Epoch 2432: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9797e-06 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.8616\n","Epoch 2433/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1947e-05 - accuracy: 1.0000\n","Epoch 2433: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 4.1567e-05 - accuracy: 1.0000 - val_loss: 4.3056 - val_accuracy: 0.4801\n","Epoch 2434/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9994\n","Epoch 2434: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 1.2654 - val_accuracy: 0.7113\n","Epoch 2435/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.7593e-04 - accuracy: 0.9997\n","Epoch 2435: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 3.7252e-04 - accuracy: 0.9997 - val_loss: 0.9704 - val_accuracy: 0.7585\n","Epoch 2436/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1356e-04 - accuracy: 1.0000\n","Epoch 2436: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1159e-04 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.8439\n","Epoch 2437/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.3066e-05 - accuracy: 1.0000\n","Epoch 2437: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 4.2778e-05 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8925\n","Epoch 2438/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2554e-05 - accuracy: 1.0000\n","Epoch 2438: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 7.2554e-05 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.7761\n","Epoch 2439/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2690e-04 - accuracy: 1.0000\n","Epoch 2439: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2573e-04 - accuracy: 1.0000 - val_loss: 3.2575 - val_accuracy: 0.6230\n","Epoch 2440/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1455e-04 - accuracy: 1.0000\n","Epoch 2440: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1455e-04 - accuracy: 1.0000 - val_loss: 1.2417 - val_accuracy: 0.7791\n","Epoch 2441/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.1334e-05 - accuracy: 1.0000\n","Epoch 2441: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.1334e-05 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.8144\n","Epoch 2442/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.3807e-06 - accuracy: 1.0000\n","Epoch 2442: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 9.3794e-06 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.8306\n","Epoch 2443/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0687e-05 - accuracy: 1.0000\n","Epoch 2443: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 46ms/step - loss: 1.0590e-05 - accuracy: 1.0000 - val_loss: 0.8011 - val_accuracy: 0.8409\n","Epoch 2444/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0672e-04 - accuracy: 1.0000\n","Epoch 2444: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.0598e-04 - accuracy: 1.0000 - val_loss: 0.8225 - val_accuracy: 0.8351\n","Epoch 2445/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4083e-05 - accuracy: 1.0000\n","Epoch 2445: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3863e-05 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.8277\n","Epoch 2446/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2308e-05 - accuracy: 1.0000\n","Epoch 2446: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2214e-05 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.8306\n","Epoch 2447/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.0037e-05 - accuracy: 1.0000\n","Epoch 2447: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.9761e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8395\n","Epoch 2448/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2136e-06 - accuracy: 1.0000\n","Epoch 2448: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1884e-06 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8527\n","Epoch 2449/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5587e-05 - accuracy: 1.0000\n","Epoch 2449: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5401e-05 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.8704\n","Epoch 2450/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5296e-05 - accuracy: 1.0000\n","Epoch 2450: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5296e-05 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.8895\n","Epoch 2451/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7423e-06 - accuracy: 1.0000\n","Epoch 2451: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7345e-06 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.8984\n","Epoch 2452/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.4738e-06 - accuracy: 1.0000\n","Epoch 2452: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4278e-06 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.8969\n","Epoch 2453/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1174e-06 - accuracy: 1.0000\n","Epoch 2453: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1174e-06 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.8999\n","Epoch 2454/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.1420e-06 - accuracy: 1.0000\n","Epoch 2454: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 6.0895e-06 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9028\n","Epoch 2455/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2931e-06 - accuracy: 1.0000\n","Epoch 2455: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2931e-06 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.8984\n","Epoch 2456/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.1211e-06 - accuracy: 1.0000\n","Epoch 2456: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 5.0904e-06 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.8940\n","Epoch 2457/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.2264e-06 - accuracy: 1.0000\n","Epoch 2457: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.2264e-06 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.8822\n","Epoch 2458/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8819e-07 - accuracy: 1.0000\n","Epoch 2458: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 8.8819e-07 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.8866\n","Epoch 2459/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.1873e-05 - accuracy: 1.0000\n","Epoch 2459: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1774e-05 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.8837\n","Epoch 2460/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2316e-06 - accuracy: 1.0000\n","Epoch 2460: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2209e-06 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.8822\n","Epoch 2461/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1859e-05 - accuracy: 1.0000\n","Epoch 2461: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.1859e-05 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.8837\n","Epoch 2462/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.6129e-06 - accuracy: 1.0000\n","Epoch 2462: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 4.6129e-06 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.8910\n","Epoch 2463/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.7633e-06 - accuracy: 1.0000\n","Epoch 2463: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7633e-06 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.8851\n","Epoch 2464/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6740e-05 - accuracy: 1.0000\n","Epoch 2464: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6586e-05 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9013\n","Epoch 2465/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.6383e-06 - accuracy: 1.0000\n","Epoch 2465: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.6383e-06 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9102\n","Epoch 2466/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.3046e-06 - accuracy: 1.0000\n","Epoch 2466: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.2463e-06 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9102\n","Epoch 2467/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.6333e-06 - accuracy: 1.0000\n","Epoch 2467: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.6097e-06 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9072\n","Epoch 2468/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2335e-06 - accuracy: 1.0000\n","Epoch 2468: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2243e-06 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9013\n","Epoch 2469/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.0349e-06 - accuracy: 1.0000\n","Epoch 2469: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.0349e-06 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9013\n","Epoch 2470/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.1484e-06 - accuracy: 1.0000\n","Epoch 2470: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 3.1484e-06 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9043\n","Epoch 2471/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1225e-06 - accuracy: 1.0000\n","Epoch 2471: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 47ms/step - loss: 2.1029e-06 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9028\n","Epoch 2472/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1894e-06 - accuracy: 1.0000\n","Epoch 2472: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1913e-06 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9043\n","Epoch 2473/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.6984e-05 - accuracy: 1.0000\n","Epoch 2473: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 6.6984e-05 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.8424\n","Epoch 2474/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.0771e-05 - accuracy: 1.0000\n","Epoch 2474: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 2.0580e-05 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8557\n","Epoch 2475/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9904e-06 - accuracy: 1.0000\n","Epoch 2475: val_accuracy did not improve from 0.91163\n","108/108 [==============================] - 5s 48ms/step - loss: 1.9904e-06 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.8999\n","Epoch 2476/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5540e-05 - accuracy: 1.0000\n","Epoch 2476: val_accuracy improved from 0.91163 to 0.92047, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 10s 94ms/step - loss: 1.5540e-05 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9205\n","Epoch 2477/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5374e-06 - accuracy: 1.0000\n","Epoch 2477: val_accuracy did not improve from 0.92047\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5374e-06 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9205\n","Epoch 2478/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7909e-06 - accuracy: 1.0000\n","Epoch 2478: val_accuracy improved from 0.92047 to 0.92489, saving model to /content/drive/My Drive/Running Plantiga Project/Data/Results/models_trained/10k_1000_250_0_resnet50_12channels_subject_id_True_None_2023-09-13 19:49:32.h5\n","108/108 [==============================] - 7s 62ms/step - loss: 2.7909e-06 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9249\n","Epoch 2479/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9088e-07 - accuracy: 1.0000\n","Epoch 2479: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 5.8575e-07 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9205\n","Epoch 2480/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5079e-06 - accuracy: 1.0000\n","Epoch 2480: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4959e-06 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9190\n","Epoch 2481/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.6270e-06 - accuracy: 1.0000\n","Epoch 2481: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 6s 49ms/step - loss: 3.5937e-06 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9087\n","Epoch 2482/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4583e-06 - accuracy: 1.0000\n","Epoch 2482: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4478e-06 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9146\n","Epoch 2483/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9370e-06 - accuracy: 1.0000\n","Epoch 2483: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 3.9185e-06 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9175\n","Epoch 2484/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7251e-06 - accuracy: 1.0000\n","Epoch 2484: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.7177e-06 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9190\n","Epoch 2485/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.8905e-06 - accuracy: 1.0000\n","Epoch 2485: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8905e-06 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9131\n","Epoch 2486/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2748e-06 - accuracy: 1.0000\n","Epoch 2486: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2633e-06 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9175\n","Epoch 2487/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 9.8435e-07 - accuracy: 1.0000\n","Epoch 2487: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 9.7600e-07 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9175\n","Epoch 2488/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8123e-06 - accuracy: 1.0000\n","Epoch 2488: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.8019e-06 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9190\n","Epoch 2489/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.4167e-06 - accuracy: 1.0000\n","Epoch 2489: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4167e-06 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9205\n","Epoch 2490/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.9326e-06 - accuracy: 1.0000\n","Epoch 2490: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 3.8972e-06 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9161\n","Epoch 2491/20000\n","108/108 [==============================] - ETA: 0s - loss: 4.0135e-06 - accuracy: 1.0000\n","Epoch 2491: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 4.0135e-06 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9146\n","Epoch 2492/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.5428e-04 - accuracy: 1.0000\n","Epoch 2492: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 5.5428e-04 - accuracy: 1.0000 - val_loss: 5.2645 - val_accuracy: 0.3417\n","Epoch 2493/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n","Epoch 2493: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 3.4219 - val_accuracy: 0.4580\n","Epoch 2494/20000\n","108/108 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n","Epoch 2494: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.0124 - val_accuracy: 0.8100\n","Epoch 2495/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.8349e-04 - accuracy: 1.0000\n","Epoch 2495: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 3.8349e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9102\n","Epoch 2496/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2641e-04 - accuracy: 1.0000\n","Epoch 2496: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2641e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9175\n","Epoch 2497/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3826e-05 - accuracy: 1.0000\n","Epoch 2497: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.3703e-05 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9205\n","Epoch 2498/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.3025e-04 - accuracy: 1.0000\n","Epoch 2498: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3025e-04 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.8498\n","Epoch 2499/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.4773e-05 - accuracy: 1.0000\n","Epoch 2499: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4773e-05 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8910\n","Epoch 2500/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.2389e-05 - accuracy: 1.0000\n","Epoch 2500: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 6.2192e-05 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.8807\n","Epoch 2501/20000\n","108/108 [==============================] - ETA: 0s - loss: 6.6632e-06 - accuracy: 1.0000\n","Epoch 2501: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 6.6632e-06 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8822\n","Epoch 2502/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.8068e-05 - accuracy: 1.0000\n","Epoch 2502: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.8068e-05 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8866\n","Epoch 2503/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.0399e-06 - accuracy: 1.0000\n","Epoch 2503: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 8.0399e-06 - accuracy: 1.0000 - val_loss: 0.6271 - val_accuracy: 0.8851\n","Epoch 2504/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.7430e-06 - accuracy: 1.0000\n","Epoch 2504: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 7.7430e-06 - accuracy: 1.0000 - val_loss: 0.6188 - val_accuracy: 0.8881\n","Epoch 2505/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5186e-06 - accuracy: 1.0000\n","Epoch 2505: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 6.4616e-06 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.8881\n","Epoch 2506/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 7.7466e-06 - accuracy: 1.0000\n","Epoch 2506: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 7.6904e-06 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.8895\n","Epoch 2507/20000\n","108/108 [==============================] - ETA: 0s - loss: 9.8663e-06 - accuracy: 1.0000\n","Epoch 2507: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 9.8663e-06 - accuracy: 1.0000 - val_loss: 0.5660 - val_accuracy: 0.8940\n","Epoch 2508/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.4098e-06 - accuracy: 1.0000\n","Epoch 2508: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 5.4318e-06 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.8940\n","Epoch 2509/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.1143e-06 - accuracy: 1.0000\n","Epoch 2509: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1143e-06 - accuracy: 1.0000 - val_loss: 0.5636 - val_accuracy: 0.8940\n","Epoch 2510/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.9203e-06 - accuracy: 1.0000\n","Epoch 2510: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 6.8565e-06 - accuracy: 1.0000 - val_loss: 0.5544 - val_accuracy: 0.8954\n","Epoch 2511/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.1566e-06 - accuracy: 1.0000\n","Epoch 2511: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 8.0841e-06 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.8940\n","Epoch 2512/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.1911e-06 - accuracy: 1.0000\n","Epoch 2512: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 5.1451e-06 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.8969\n","Epoch 2513/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5226e-05 - accuracy: 1.0000\n","Epoch 2513: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5093e-05 - accuracy: 1.0000 - val_loss: 0.5587 - val_accuracy: 0.8969\n","Epoch 2514/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0259e-05 - accuracy: 1.0000\n","Epoch 2514: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0259e-05 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.8969\n","Epoch 2515/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.2857e-06 - accuracy: 1.0000\n","Epoch 2515: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 2.2724e-06 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.8925\n","Epoch 2516/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.0666e-05 - accuracy: 1.0000\n","Epoch 2516: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0666e-05 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.8954\n","Epoch 2517/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.1868e-06 - accuracy: 1.0000\n","Epoch 2517: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 2.1669e-06 - accuracy: 1.0000 - val_loss: 0.5432 - val_accuracy: 0.8925\n","Epoch 2518/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.0110e-06 - accuracy: 1.0000\n","Epoch 2518: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 3.0110e-06 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.8940\n","Epoch 2519/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.2541e-06 - accuracy: 1.0000\n","Epoch 2519: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 3.2279e-06 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.8910\n","Epoch 2520/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 5.9282e-06 - accuracy: 1.0000\n","Epoch 2520: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 5.8910e-06 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.8940\n","Epoch 2521/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.3557e-06 - accuracy: 1.0000\n","Epoch 2521: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 2.3369e-06 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.8895\n","Epoch 2522/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.0518e-05 - accuracy: 1.0000\n","Epoch 2522: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.0424e-05 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8895\n","Epoch 2523/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.5977e-06 - accuracy: 1.0000\n","Epoch 2523: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 2.5763e-06 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.8895\n","Epoch 2524/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.5001e-06 - accuracy: 1.0000\n","Epoch 2524: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4926e-06 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.8925\n","Epoch 2525/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2707e-05 - accuracy: 1.0000\n","Epoch 2525: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.2590e-05 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.8881\n","Epoch 2526/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.9795e-06 - accuracy: 1.0000\n","Epoch 2526: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.9795e-06 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.8881\n","Epoch 2527/20000\n","108/108 [==============================] - ETA: 0s - loss: 3.2225e-06 - accuracy: 1.0000\n","Epoch 2527: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 3.2225e-06 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.8895\n","Epoch 2528/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.9082e-06 - accuracy: 1.0000\n","Epoch 2528: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 2.8875e-06 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8881\n","Epoch 2529/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.7114e-06 - accuracy: 1.0000\n","Epoch 2529: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 2.7114e-06 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.8925\n","Epoch 2530/20000\n","108/108 [==============================] - ETA: 0s - loss: 8.8103e-06 - accuracy: 1.0000\n","Epoch 2530: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 8.8103e-06 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8925\n","Epoch 2531/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 4.1199e-06 - accuracy: 1.0000\n","Epoch 2531: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 4.0848e-06 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8925\n","Epoch 2532/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 8.4173e-06 - accuracy: 1.0000\n","Epoch 2532: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 8.3411e-06 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.8851\n","Epoch 2533/20000\n","108/108 [==============================] - ETA: 0s - loss: 5.7257e-06 - accuracy: 1.0000\n","Epoch 2533: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 5.7257e-06 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8940\n","Epoch 2534/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.8098e-06 - accuracy: 1.0000\n","Epoch 2534: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.7946e-06 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.8925\n","Epoch 2535/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.2412e-06 - accuracy: 1.0000\n","Epoch 2535: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2412e-06 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.8925\n","Epoch 2536/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.6796e-06 - accuracy: 1.0000\n","Epoch 2536: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.6796e-06 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.8895\n","Epoch 2537/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4989e-06 - accuracy: 1.0000\n","Epoch 2537: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.4880e-06 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8881\n","Epoch 2538/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.4385e-06 - accuracy: 1.0000\n","Epoch 2538: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.4265e-06 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8940\n","Epoch 2539/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.5515e-06 - accuracy: 1.0000\n","Epoch 2539: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 2.5515e-06 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.8969\n","Epoch 2540/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 2.4957e-06 - accuracy: 1.0000\n","Epoch 2540: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 2.4730e-06 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.8999\n","Epoch 2541/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.3799e-06 - accuracy: 1.0000\n","Epoch 2541: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.3764e-06 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.8954\n","Epoch 2542/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.2917e-05 - accuracy: 1.0000\n","Epoch 2542: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.2799e-05 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9043\n","Epoch 2543/20000\n","108/108 [==============================] - ETA: 0s - loss: 7.2797e-04 - accuracy: 0.9997\n","Epoch 2543: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 7.2797e-04 - accuracy: 0.9997 - val_loss: 2.7214 - val_accuracy: 0.6024\n","Epoch 2544/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9982\n","Epoch 2544: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 0.0035 - accuracy: 0.9983 - val_loss: 2.2652 - val_accuracy: 0.5685\n","Epoch 2545/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 6.5337e-04 - accuracy: 1.0000\n","Epoch 2545: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 6.4768e-04 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.8424\n","Epoch 2546/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.5342e-04 - accuracy: 1.0000\n","Epoch 2546: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.5342e-04 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.8513\n","Epoch 2547/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 3.4313e-05 - accuracy: 1.0000\n","Epoch 2547: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 3.4060e-05 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8498\n","Epoch 2548/20000\n","108/108 [==============================] - ETA: 0s - loss: 2.2005e-05 - accuracy: 1.0000\n","Epoch 2548: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 2.2005e-05 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.8498\n","Epoch 2549/20000\n","108/108 [==============================] - ETA: 0s - loss: 1.1762e-05 - accuracy: 1.0000\n","Epoch 2549: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.1762e-05 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.8513\n","Epoch 2550/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.7847e-05 - accuracy: 1.0000\n","Epoch 2550: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 47ms/step - loss: 1.8269e-05 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8542\n","Epoch 2551/20000\n","107/108 [============================\u003e.] - ETA: 0s - loss: 1.6705e-05 - accuracy: 1.0000\n","Epoch 2551: val_accuracy did not improve from 0.92489\n","108/108 [==============================] - 5s 48ms/step - loss: 1.6564e-05 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8571\n","Epoch 2552/20000\n"," 88/108 [=======================\u003e......] - ETA: 0s - loss: 1.8165e-04 - accuracy: 1.0000"]},{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-1-43e60a6c4e9e\u003e\", line 64, in \u003ccell line: 64\u003e\n","    script_classification.script_classification(data_name, subjects, val_split, test_split, flag_shuffle_train, flag_plot, output_variable,\n","  File \"/content/drive/My Drive/Running Plantiga Project/Code/script_classification.py\", line 227, in script_classification\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/lib/python3.10/traceback.py\", line 39, in format_list\n","    return StackSummary.from_list(extracted_list).format()\n","  File \"/usr/lib/python3.10/traceback.py\", line 401, in from_list\n","    filename, lineno, name, line = frame\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-1-43e60a6c4e9e\u003e\", line 64, in \u003ccell line: 64\u003e\n","    script_classification.script_classification(data_name, subjects, val_split, test_split, flag_shuffle_train, flag_plot, output_variable,\n","  File \"/content/drive/My Drive/Running Plantiga Project/Code/script_classification.py\", line 227, in script_classification\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/lib/python3.10/traceback.py\", line 39, in format_list\n","    return StackSummary.from_list(extracted_list).format()\n","  File \"/usr/lib/python3.10/traceback.py\", line 401, in from_list\n","    filename, lineno, name, line = frame\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n"]},{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-1-43e60a6c4e9e\u003e\", line 64, in \u003ccell line: 64\u003e\n","    script_classification.script_classification(data_name, subjects, val_split, test_split, flag_shuffle_train, flag_plot, output_variable,\n","  File \"/content/drive/My Drive/Running Plantiga Project/Code/script_classification.py\", line 227, in script_classification\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/lib/python3.10/traceback.py\", line 39, in format_list\n","    return StackSummary.from_list(extracted_list).format()\n","  File \"/usr/lib/python3.10/traceback.py\", line 401, in from_list\n","    filename, lineno, name, line = frame\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["import os, os.path, datetime\n","import keras\n","from google.colab import drive, runtime\n","drive.mount('/content/drive')\n","import time\n","\n","# import PredictPower_functions\n","%cd /content/drive/My\\ Drive/Running Plantiga Project/Code\n","import script_classification as script_classification\n","#import PredictPower_functions as ppf\n","#import openloop_algorithms as oa\n","\n","\n","#check if GPU is available\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","\n","%cd /content/drive/My\\ Drive/Running Plantiga Project\n","dir_root = os.getcwd() + '/'\n","\n","\"\"\"some variables\"\"\"\n","\n","data_name = \"10k_1000_250_0\"\n","subjects = [1,2,3,8,9,20,21,24,28,32,33,35,36,42,45,49,55,79,108,110,111,122,131,133]\n","test_subjects = [1,2,3,8,9,20] # if empty it will not use test subjects\n","learning_rate = 0.00001 #[] is default of 0.001\n","\n","window_length = 10000\n","trials = [1,2,3]\n","model_to_use = 'resnet50_12channels' #'parallel_channels_LSTM, 'parallel_channels_conv1D', 'resnet50', 'resnet50_12channels'\n","epochs = 20000\n","\n","flag_shuffle_train = 0 # maybe this can go, if we are shuffling subjects beforehand anyways\n","flag_shuffle_subjects = 0\n","flag_plot = 0\n","flag_top_5_accuracy = 0\n","\n","output_variable = \"subject_id\" #\"speed\", \"subject_id\", \"seconds_10k\"\n","percentage_of_data_to_be_used = 1 # number between 0 and 100. 100 is all data, everything else takes the percentage\n","\n","\n","val_split = 0.2\n","test_split = 0.2\n","\n","dropout = 0\n","batch_size = 32\n","\n","early_stopping_min_delta = 0\n","early_stopping_patience = 3000\n","reinitialize_epochs = 1000\n","\n","\n","kernel_size_convolution = 250\n","input_model = keras.Input(shape = (100,60,12,1)) #keras.Input(shape = (126,40,12,1))  #keras.Input(shape = (10000,12)) # input for first layer\n","input_resnet = keras.Input(shape=(126,40,12)) # input after my own layers into the resnet\n","resnet_trainable = True\n","weights_to_use = None #'imagenet', None\n","\n","\n","script_classification.script_classification(data_name, subjects, val_split, test_split, flag_shuffle_train, flag_plot, output_variable,\n","                          epochs, dropout, batch_size, early_stopping_min_delta, early_stopping_patience,\n","                          dir_root, trials, window_length, kernel_size_convolution, model_to_use,\n","                          weights_to_use, input_model, input_resnet, resnet_trainable, reinitialize_epochs, flag_shuffle_subjects,\n","                          flag_top_5_accuracy, test_subjects, learning_rate, percentage_of_data_to_be_used)\n","\n","time.sleep(10)\n","!kill -9 -1\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNfmArPIgVNKJRTptZs5etI","machine_shape":"hm","name":"","provenance":[{"file_id":"12jc-IHy7i9xB7lcpHPP7vZFTFN1I9Fhk","timestamp":1678214894535}],"version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}